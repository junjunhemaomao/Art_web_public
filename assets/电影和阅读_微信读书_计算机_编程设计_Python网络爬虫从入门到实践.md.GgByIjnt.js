import{_ as a,o as t,c as o,a6 as l}from"./chunks/framework.BB0md0jN.js";const d=JSON.parse('{"title":"Python网络爬虫从入门到实践","description":"","frontmatter":{"layout":"doc","title":"Python网络爬虫从入门到实践","readingTime":"4 min read"},"headers":[],"relativePath":"电影和阅读/微信读书/计算机_编程设计/Python网络爬虫从入门到实践.md","filePath":"电影和阅读/微信读书/计算机_编程设计/Python网络爬虫从入门到实践.md"}'),r={name:"电影和阅读/微信读书/计算机_编程设计/Python网络爬虫从入门到实践.md"};function n(i,e,s,u,h,c){return t(),o("div",null,[...e[0]||(e[0]=[l('<h1 id="python网络爬虫从入门到实践" tabindex="-1">Python网络爬虫从入门到实践 <a class="header-anchor" href="#python网络爬虫从入门到实践" aria-label="Permalink to &quot;Python网络爬虫从入门到实践&quot;">​</a></h1><p><img src="https://cdn.weread.qq.com/weread/cover/46/yuewen_25663552/t6_yuewen_256635521735272307.jpg" alt=" Python网络爬虫从入门到实践"></p><ul><li><strong>书名</strong>： Python网络爬虫从入门到实践</li><li><strong>作者</strong>： 唐松 陈智铨</li><li><strong>简介</strong>： 本书将介绍如何使用Python编写网络爬虫程序获取互联网上的大数据。本书包括三部分内容：基础部分、进阶部分和项目实践。基础部分主要介绍爬虫的三个步骤：获取网页、解析网页和存储数据，并通过诸多小例子的讲解，让读者能够从基础内容开始系统性地学习爬虫，并在实践中提升Python爬虫水平。进阶部分包括多线程的并发和并行爬虫、分布式爬虫、更换IP等，帮助读者进一步提升爬虫水平。项目实践部分使用本书介绍的爬虫技术对几个真实的网站进行抓取，让读者能在读完本书后根据自己的需求写出爬虫程序 。 无论是否有编程基础，只要是对爬虫技术感兴趣的读者，本书就能带领读者从入门到进阶，再到实战，一步步了解爬虫，最终写出自己的爬虫程序。</li><li><strong>出版时间</strong>： 2017-09-05 00:00:00</li><li><strong>ISBN</strong>： 9787111578413</li><li><strong>分类</strong>： 计算机-编程设计</li><li><strong>出版社</strong>： 机械工业出版社</li><li><strong>PC地址</strong>： <a href="https://weread.qq.com/web/reader/aa3322a071879840aa36175" target="_blank" rel="noreferrer">https://weread.qq.com/web/reader/aa3322a071879840aa36175</a></li></ul><h4 id="_2-3-2-第二步-提取需要的数据" tabindex="-1">2.3.2 第二步：提取需要的数据 <a class="header-anchor" href="#_2-3-2-第二步-提取需要的数据" aria-label="Permalink to &quot;2.3.2 第二步：提取需要的数据&quot;">​</a></h4><blockquote><p>📌 对初学者来说，使用BeautifulSoup从网页中提取需要的数据更加简单易用。 ⏱ 2020-01-20 05:00:38</p></blockquote><h2 id="第3章-静态网页抓取" tabindex="-1">第3章 静态网页抓取 <a class="header-anchor" href="#第3章-静态网页抓取" aria-label="Permalink to &quot;第3章 静态网页抓取&quot;">​</a></h2><blockquote><p>📌 相对而言，使用AJAX动态加载网页的数据不一定会出现在HTML代码中，这就给爬虫增加了困难。 ⏱ 2020-01-20 05:07:09</p></blockquote><h4 id="_3-3-2-定制请求头" tabindex="-1">3.3.2 定制请求头 <a class="header-anchor" href="#_3-3-2-定制请求头" aria-label="Permalink to &quot;3.3.2 定制请求头&quot;">​</a></h4><blockquote><p>📌 对于爬虫而言，请求头十分重要，尽管在上一个示例中并没有制定请求头。如果没有指定请求头或请求的请求头和实际网页不一致，就可能无法返回正确的结果。 ⏱ 2020-01-20 05:10:16</p></blockquote><h4 id="_4-3-1-selenium的安装与基本介绍" tabindex="-1">4.3.1 Selenium的安装与基本介绍 <a class="header-anchor" href="#_4-3-1-selenium的安装与基本介绍" aria-label="Permalink to &quot;4.3.1 Selenium的安装与基本介绍&quot;">​</a></h4><blockquote><p>📌 在Selenium之前的版本中，这样做是不会报错的，但是Selenium新版无法正常运行。我们要下载geckodriver， ⏱ 2020-01-21 18:24:49</p></blockquote><h4 id="_4-3-3-selenium获取文章的所有评论" tabindex="-1">4.3.3 Selenium获取文章的所有评论 <a class="header-anchor" href="#_4-3-3-selenium获取文章的所有评论" aria-label="Permalink to &quot;4.3.3 Selenium获取文章的所有评论&quot;">​</a></h4><blockquote><p>📌 其中，xpath和css_selector是比较好的方法，一方面比较清晰，另一方面相对其他方法定位元素比较准确。 ⏱ 2020-01-21 18:23:09</p></blockquote><h4 id="_4-3-4-selenium的高级操作" tabindex="-1">4.3.4 Selenium的高级操作 <a class="header-anchor" href="#_4-3-4-selenium的高级操作" aria-label="Permalink to &quot;4.3.4 Selenium的高级操作&quot;">​</a></h4><blockquote><p>📌 使用Selenium和使用浏览器“检查”的方法爬取动态网页相比，因为Selenium要在整个网页加载出来后才开始爬取内容，速度往往较慢。 ⏱ 2020-01-21 18:23:56</p></blockquote><blockquote><p>📌 控制CSS。因为抓取过程中仅仅抓取页面的内容，CSS样式文件是用来控制页面的外观和元素放置位置的，对内容并没有影响，所以我们可以限制网页加载CSS，从而减少抓取时间。 ⏱ 2020-01-21 18:24:25</p></blockquote>',16)])])}const m=a(r,[["render",n]]);export{d as __pageData,m as default};
