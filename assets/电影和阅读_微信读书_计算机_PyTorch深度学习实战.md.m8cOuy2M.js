import{_ as e,o as t,c,a6 as l}from"./chunks/framework.BB0md0jN.js";const n=JSON.parse('{"title":"PyTorch深度学习实战","description":"","frontmatter":{"layout":"doc","title":"PyTorch深度学习实战","readingTime":"41 min read"},"headers":[],"relativePath":"电影和阅读/微信读书/计算机/PyTorch深度学习实战.md","filePath":"电影和阅读/微信读书/计算机/PyTorch深度学习实战.md"}'),u={name:"电影和阅读/微信读书/计算机/PyTorch深度学习实战.md"};function b(r,o,a,q,p,k){return t(),c("div",null,[...o[0]||(o[0]=[l('<h1 id="pytorch深度学习实战" tabindex="-1">PyTorch深度学习实战 <a class="header-anchor" href="#pytorch深度学习实战" aria-label="Permalink to &quot;PyTorch深度学习实战&quot;">​</a></h1><p><img src="https://wfqqreader-1252317822.image.myqcloud.com/cover/589/43134589/t6_43134589.jpg" alt=" PyTorch深度学习实战"></p><ul><li><strong>书名</strong>： PyTorch深度学习实战</li><li><strong>作者</strong>： 伊莱·史蒂文斯 卢卡·安蒂加 托马斯·菲曼</li><li><strong>简介</strong>： 虽然很多深度学习工具都使用Python，但PyTorch库是真正具备Python风格的。对于任何了解NumPy和scikit-learn等工具的人来说，上手PyTorch轻而易举。PyTorch在不牺牲高级特性的情况下简化了深度学习，它非常适合构建快速模型，并且可以平稳地从个人应用扩展到企业级应用。由于像苹果、Facebook和摩根大通这样的公司都使用PyTorch，所以当你掌握了PyTorth，就会拥有更多的职业选择。本书是教你使用PyTorch创建神经网络和深度学习系统的实用指南。它帮助读者快速从零开始构建一个真实示例：肿瘤图像分类器。在此过程中，它涵盖了整个深度学习管道的关键实践，包括PyTorch张量API、用Python加载数据、监控训练以及将结果进行可视化展示。本书主要内容：（1）训练深层神经网络；（2）实现模块和损失函数；（3）使用PyTorchHub预先训练的模型；（4）探索在JupyterNotebooks中编写示例代码。</li><li><strong>出版时间</strong>： 2022-02-01 00:00:00</li><li><strong>ISBN</strong>： 9787115577672</li><li><strong>分类</strong>： 计算机-数据库</li><li><strong>出版社</strong>： 人民邮电出版社</li><li><strong>PC地址</strong>： <a href="https://weread.qq.com/web/reader/73d32f9072922e7d73d5a39" target="_blank" rel="noreferrer">https://weread.qq.com/web/reader/73d32f9072922e7d73d5a39</a></li></ul><h2 id="序" tabindex="-1">序 <a class="header-anchor" href="#序" aria-label="Permalink to &quot;序&quot;">​</a></h2><blockquote><p>📌 。PyTorch的大部分基础代码源于Ronan Collobert等人在2007年发起的Torch7项目，该项目源于Yann LeCun和Leon Bottou首创的编程语言——Lush。正是鉴于这段丰富的历史经验，我们才能关注需要改变的东西，而不是从零开始。 ⏱ 2023-09-12 08:54:01</p></blockquote><h2 id="前-言" tabindex="-1">前 言 <a class="header-anchor" href="#前-言" aria-label="Permalink to &quot;前 言&quot;">​</a></h2><blockquote><p>📌 我们花了一些时间才意识到，深度学习代表了一种全新的软件编写方式——一种新的多用途算法，可以通过观察数据来学习如何解决复杂的问题。 ⏱ 2023-09-12 08:54:58</p></blockquote><blockquote><p>📌 关于计算机能做什么的视野一夜之间就扩展了，计算机能做什么不再受限于程序员的大脑，而受限于数据、神经网络结构和训练过程。 ⏱ 2023-09-12 08:59:27</p></blockquote><blockquote><p>📌 我们有一种感觉：有一些大型的东西正在起步，这些东西具有适当的复杂性，并且只需要很少的认知开销。 ⏱ 2023-09-12 09:00:18</p></blockquote><h2 id="关于本书" tabindex="-1">关于本书 <a class="header-anchor" href="#关于本书" aria-label="Permalink to &quot;关于本书&quot;">​</a></h2><blockquote><p>📌 。我们力图介绍深度学习底层的核心思想，并向读者展示PyTorch如何将其实现。 ⏱ 2023-09-12 09:01:44</p></blockquote><blockquote><p>📌 本书并不是一本参考书，相反，它是一本概念性的指南，旨在引导你在网上独立探索更高级的材料。因此，我们关注的是PyTorch提供的一部分特性，最值得注意的是循环神经网络， ⏱ 2023-09-12 09:02:05</p></blockquote><blockquote><p>📌 。我们将介绍PyTorch API和一些PyTorch库背后的特性，并训练一个初始的分类模型。 ⏱ 2023-09-12 09:05:56</p></blockquote><blockquote><p>📌 PyTorch的基本构建组件——张量，介绍张量的一些API，并深入底层介绍一些实现细节。 ⏱ 2023-09-12 09:10:03</p></blockquote><blockquote><p>📌 展示不同类型的数据如何被表示为张量，以及深度学习模型期望构造什么样的张量。 ⏱ 2023-09-12 09:10:08</p></blockquote><blockquote><p>📌 介绍构建一个用于图像分类的全连接层模型 ⏱ 2023-09-12 09:10:38</p></blockquote><blockquote><p>📌 第3部分为第15章，主要介绍部署相关内容，概述如何将PyTorch模型部署到简单的Web服务中，或将它们嵌入C++程序中，抑或将它们发布到移动电话上。 ⏱ 2023-09-12 09:24:41</p></blockquote><blockquote><p>📌 。以_t作为后缀的变量是用于CPU存储器的张量，以_g作为后缀的变量用于GPU存储器，以_a作为后缀的变量是NumPy数组。 ⏱ 2023-09-12 09:26:31</p></blockquote><blockquote><p>📌 我们建议Windows用户安装Anaconda或Miniconda。 ⏱ 2023-09-12 09:27:34</p></blockquote><blockquote><p>📌 我们提供了一个名为requirements.txt的文件，pip可以按照该文件来安装依赖项。由于目前的苹果笔记本计算机没有支持CUDA的GPU，因此对于采用macOS的PyTorch预编译软件包只支持CPU。 ⏱ 2023-09-12 09:31:52</p></blockquote><h2 id="第1部分-pytorch核心" tabindex="-1">第1部分 PyTorch核心 <a class="header-anchor" href="#第1部分-pytorch核心" aria-label="Permalink to &quot;第1部分 PyTorch核心&quot;">​</a></h2><blockquote><p>📌 。第3章就稍微有点儿严肃了，将介绍PyTorch程序中使用的基本数据结构：张量。 ⏱ 2023-09-22 09:46:07</p></blockquote><h3 id="第1章-深度学习和pytorch库简介" tabindex="-1">第1章 深度学习和PyTorch库简介 <a class="header-anchor" href="#第1章-深度学习和pytorch库简介" aria-label="Permalink to &quot;第1章 深度学习和PyTorch库简介&quot;">​</a></h3><blockquote><p>📌 深度学习使用大量数据来近似输入和输出相距很远的复杂函数，如输入是图像，输出是对输入进行描述的一行文本；或输入是书面文字，输出是朗读该文字的自然语音。 ⏱ 2023-03-03 08:41:37</p></blockquote><h4 id="_1-1-深度学习革命" tabindex="-1">1.1 深度学习革命 <a class="header-anchor" href="#_1-1-深度学习革命" aria-label="Permalink to &quot;1.1 深度学习革命&quot;">​</a></h4><blockquote><p>📌 过去10年，被称为机器学习的一类系统重度依赖于特征工程。特征是对输入数据的转换，它有助于下游算法（如分类器）在新数据上产生正确的结果。特征工程包括提出正确的转换，以便下游算法能够完成任务。 ⏱ 2023-03-03 08:41:17</p></blockquote><blockquote><p>📌 深度学习实践者的重点不是手工制作这些表征，而是操作数学实体，以便能够自动地从训练数据中发现表征。通常，这些自动创建的表征比手工创建的更好！ ⏱ 2023-03-03 08:41:00</p></blockquote><blockquote><p>📌 在训练期间，我们使用一个评判标准、一个模型输出的实值函数和一份参考数据，给模型的期望输出和实际输出之间的差异提供一个分数（通常分数越低越好）。训练包括通过逐步修改我们的深度学习机 ⏱ 2023-03-03 08:45:01</p></blockquote><blockquote><p>📌 随着数据和计算需求的增加，深度学习不再需要手工提取特征 ⏱ 2023-03-03 08:44:47</p></blockquote><h4 id="_1-2-pytorch深度学习" tabindex="-1">1.2 PyTorch深度学习 <a class="header-anchor" href="#_1-2-pytorch深度学习" aria-label="Permalink to &quot;1.2 PyTorch深度学习&quot;">​</a></h4><blockquote><p>📌 深度学习机的核心是一个相当复杂的数学函数，它将输入映射到输出。为了便于表达这个函数，PyTorch提供了一个核心数据结构——张量，它是一个多维数组，与NumPy数组有许多相似之处。 ⏱ 2023-09-28 12:47:50</p></blockquote><blockquote><p>📌 读完本书后，我们希望你能够获得数据源，并能根据优秀的官方文档来构建一个深度学习项目。 ⏱ 2023-03-03 08:48:12</p></blockquote><blockquote><p>📌 使用应用知识武装新一代科学家、工程师和来自广泛学科的实践者迈出的一步，这些知识将成为未来几十年许多软件项目的关键。 ⏱ 2023-03-03 08:49:07</p></blockquote><h4 id="_1-3-为什么用pytorch" tabindex="-1">1.3 为什么用PyTorch <a class="header-anchor" href="#_1-3-为什么用pytorch" aria-label="Permalink to &quot;1.3 为什么用PyTorch&quot;">​</a></h4><blockquote><p>📌 。PyTorch为我们提供了一种数据类型，即张量，通常用来存储数字、向量、矩阵和数组。此外，PyTorch还提供了操作它们的函数，我们可以使用这些函数来增量编程 ⏱ 2023-03-03 08:51:35</p></blockquote><blockquote><p>📌 PyTorch具备2个特性，使得它与深度学习关联紧密。首先，它使用GPU加速计算，通常比在CPU上执行相同的计算速度快50倍。其次，PyTorch提供了支持通用数学表达式数值优化的工具，该工具用于训练深度学习模型。 ⏱ 2023-03-03 08:53:07</p></blockquote><blockquote><p>📌 PyTorch可以说是最无缝地将深度学习领域的思想转化为Python代码的软件之一。因此，PyTorch在研究中得到广泛的采用，国际会议上的高引用次数就证明了这一点[3]。 ⏱ 2023-03-03 08:53:36</p></blockquote><blockquote><p>📌 当前深度学习发展迅速，以至于当你读到本书的印刷版时，它可能已经过时了。如果你不了解这里提到的一些库也很正常。 ⏱ 2023-03-03 08:56:49</p></blockquote><blockquote><p>📌 Theano和TensorFlow是最早的低级别库，它们使用一个模型，该模型让用户自定义一个计算图，然后执行它。 ⏱ 2023-03-03 08:57:19</p></blockquote><blockquote><p>📌 PyTorch的势头越来越好。它还在生产解决方案方面积累了经验。有趣的是，随着TorchScript和急切模式的出现，PyTorch和TensorFlow的特征集开始趋同，尽管在这些特征的呈现和整体体验上仍然存在很大的差异。 ⏱ 2024-11-07 09:22:53</p></blockquote><h4 id="_1-4-pytorch如何支持深度学习概述" tabindex="-1">1.4 PyTorch如何支持深度学习概述 <a class="header-anchor" href="#_1-4-pytorch如何支持深度学习概述" aria-label="Permalink to &quot;1.4 PyTorch如何支持深度学习概述&quot;">​</a></h4><blockquote><p>📌 事实上，由于性能原因，PyTorch大部分是用C++和CUDA编写的，CUDA是一种来自英伟达的类C++的语言，可以被编译并在GPU上以并行方式运行。 ⏱ 2023-03-03 09:07:41</p></blockquote><blockquote><p>📌 大多数情况下我们都是使用Python来与PyTorch交互的， ⏱ 2023-03-03 09:19:37</p></blockquote><blockquote><p>📌 PyTorch的核心是一个提供多维数组（张量）以及由torch模块提供大量操作的库。 ⏱ 2023-03-03 09:27:43</p></blockquote><blockquote><p>📌 PyTorch中，将运算从CPU转移到GPU不需要额外的函数调用 ⏱ 2023-03-03 09:28:24</p></blockquote><blockquote><p>📌 通过PyTorch底层自动求导引擎来调度。 ⏱ 2023-03-03 09:28:14</p></blockquote><blockquote><p>📌 用于构建神经网络的PyTorch核心模块位于torch.nn中，它提供了通用的神经网络层和其他架构组件。全连接层、卷积层、激活函数和损失函数都可以在这里找到 ⏱ 2023-09-30 13:08:06</p></blockquote><blockquote><p>📌 为了训练模型，我们需要一些额外的东西：模型训练的数据源、一个使模型适应训练数据的优化器，以及一种把模型和数据传输到硬件的方法，该硬件用于执行模型训练所需的计算。 ⏱ 2023-09-30 13:09:37</p></blockquote><blockquote><p>📌 数据预处理是我们自定义数据（无论什么样的格式）与PyTorch中torch.utils.data包下的Dataset类提供的标准张量之间的桥梁。由于不同问题处理过程截然不同，因此我们需要自己定义数据源。 ⏱ 2023-03-03 09:45:48</p></blockquote><blockquote><p>📌 我们希望并行化数据加载。但是，由于Python提供的许多操作都不具有简单、高效的并行处理能力，因此我们需要多个进程来加载我们的数据，以便将它们组装成一个批次，即组装成一个包含多个样本的张量。这是相当复杂的，但由于它也是相对通用的，PyTorch很容易在DataLoader类中实现这些功能。它的实例可以生成子进程在后台从数据集中加载数据，提前将数据准备就绪，一旦训练循环开始就可以立即使用。我们将在第7章介绍和使用Dataset和DataLoader。 ⏱ 2023-09-30 13:31:06</p></blockquote><blockquote><p>📌 有了获取成批样本的机制，我们可以转向图1.2中心的训练循环。通常训练循环被实现为标准的Python for循环。 ⏱ 2023-03-03 12:52:22</p></blockquote><blockquote><p>📌 在训练循环的每个步骤中，我们根据从数据加载器获得的样本来评估模型。然后我们使用某种准则或损失函数将模型的输出与期望的输出（目标）进行比较。PyTorch除了提供构建模型的组件，也有各种损失函数供我们使用，torch.nn包中也提供这些函数。 ⏱ 2023-09-30 14:41:50</p></blockquote><blockquote><p>📌 但是我们还需要一个优化器来进行更新，这是PyTorch在torch.optiom中为我们提供的。 ⏱ 2023-09-30 14:42:07</p></blockquote><blockquote><p>📌 训练循环可能是深度学习项目中最乏味和耗时的部分。训练循环结束后，我们将得到一个模型，该模型的参数已经在我们的任务上得到了优化 ⏱ 2024-11-08 09:39:09</p></blockquote><blockquote><p>📌 部署部分可能涉及将模型放在生产服务器上，或将模型导出到云中，或者我们可将它与更大的应用程序集成，抑或在手机上运行它。部署操作中一个特定的步骤是导出模型 ⏱ 2024-11-08 09:40:48</p></blockquote><blockquote><p>📌 PyTorch还提供了一种通过TorchScript提前编译模型的方法。使用TorchScript，PyTorch可以将模型序列化为一组独立于Python调用，如在C++程序或在移动设备上调用的指令集。我们可以把模型想象成一个具有有限指令集的虚拟机，用于特定的张量操作。 ⏱ 2024-11-08 09:41:58</p></blockquote><h4 id="_1-5-硬件和软件要求" tabindex="-1">1.5 硬件和软件要求 <a class="header-anchor" href="#_1-5-硬件和软件要求" aria-label="Permalink to &quot;1.5 硬件和软件要求&quot;">​</a></h4><blockquote><p>📌 通过混合源代码、运算结果和Markdown格式的文本单元格，我们可以生成漂亮的交互式文档。 ⏱ 2023-09-30 14:55:34</p></blockquote><h3 id="第2章-预训练网络" tabindex="-1">第2章 预训练网络 <a class="header-anchor" href="#第2章-预训练网络" aria-label="Permalink to &quot;第2章 预训练网络&quot;">​</a></h3><blockquote><p>📌 ，这些模型已经在开放的大规模数据集上训练过。我们可以把预训练的神经网络看作一个接收输入并生成输出的程序， ⏱ 2023-09-30 15:11:13</p></blockquote><blockquote><p>📌 使用现成的模型是快速启动深度学习项目的一种方法，因为它利用了设计模型的研究人员的专业知识，以及花费了训练权重的计算时间。 ⏱ 2023-09-30 15:18:36</p></blockquote><blockquote><p>📌 我们将探讨3种常用的预训练模型：一种可以根据内容对图像进行标记的模型，一种可以从真实图像中生成新图像的模型，还有一种可以使用正确的英语句子来描述图像内容的模型。 ⏱ 2024-11-08 21:34:48</p></blockquote><blockquote><p>📌 学习使用PyTorch运行预先训练好的模型是一项有用的技能。如果模型是在大型数据集上训练的，那么这一点特别有用。 ⏱ 2024-11-08 21:46:28</p></blockquote><h4 id="_2-1-一个识别图像主体的预训练网络" tabindex="-1">2.1 一个识别图像主体的预训练网络 <a class="header-anchor" href="#_2-1-一个识别图像主体的预训练网络" aria-label="Permalink to &quot;2.1 一个识别图像主体的预训练网络&quot;">​</a></h4><blockquote><p>📌 ImageNet是一个由斯坦福大学维护的包含1400多万幅图像的非常大的数据集。所有图像都用来自WordNet数据集的名词层次结构标记，而WordNet数据集又是一个大型的英语词汇数据库。 ⏱ 2023-09-30 15:45:58</p></blockquote><blockquote><p>📌 具体来说，图像分类任务包括获取一个输入图像，并从1000个类别中生成5个标签的列表，列表按置信度排序，描述图像的内容。 ⏱ 2023-09-30 15:47:34</p></blockquote><blockquote><p>📌 我们最终能够拍摄自己的图像并将其输入预训练模型中，如图2.2所示。模型将为该图像生成一个预测的标签列表，我们可以检查该列表以查看模型认为我们的图像是什么。模型对有些图像的预测是准确的，而有些则不是。 ⏱ 2023-09-30 16:02:13</p></blockquote><blockquote><p>📌 输入的图像将首先被预处理成一个多维数组类torch.Tensor的实例。它是一个具有高度和宽度的RGB图像，因此这个张量将有3个维度：RGB通道和2个特定大小的空间图像维度。 ⏱ 2023-09-30 16:02:55</p></blockquote><blockquote><p>📌 根据权重，最高的分数对应最可能的类。然后将每个类一对一地映射到标签上。该输出被包含在一个含有1000个元素的torch.Tensor张量中，每个元素表示与该类相关的分数。 ⏱ 2024-11-09 18:51:14</p></blockquote><blockquote><p>📌 TorchVision项目，该项目包含一些表现优异的、关于计算机视觉的神经网络架构，如AlexNet、ResNet和Inception-v3等。 ⏱ 2023-09-30 16:24:46</p></blockquote><blockquote><p>📌 现在，让我们加载并运行这2个网络：首先是AlexNet，它是在图像识别方面早期具有突破性的网络之一；然后是残差网络，简称ResNet，它在2015年的ILSVRC中获胜。 ⏱ 2024-11-09 19:10:35</p></blockquote><blockquote><p>📌 首字母大写的名称指的是实现了许多流行模型的Python类，它们的体系结构不同，即输入和输出之间操作的编排不同。首字母小写的名称指的是一些便捷函数，它们返回这些类实例化的模型，有时使用不同的参数集。 ⏱ 2023-09-30 16:27:49</p></blockquote><blockquote><p>📌 随之而来的是不断的改进，更现代的架构和训练方法使得前5名的错误率低至3%。 ⏱ 2023-09-30 16:29:24</p></blockquote><blockquote><p>📌 我们可以将每个块看作一个过滤器，一个接收一幅或多幅图像作为输入并生成其他图像作为输出的函数。 ⏱ 2023-09-30 16:30:28</p></blockquote><blockquote><p>📌 在过滤器堆栈中，最后一个过滤器产生的图像被排列成一个拥有4096个元素的一维向量，并被分类以产生1000个输出，每个输出对应一个类。 ⏱ 2023-09-30 16:31:23</p></blockquote><blockquote><p>📌 为了在输入图像上运行AlexNet架构，我们可以创建一个AlexNet类的实例， ⏱ 2023-09-30 16:33:21</p></blockquote><blockquote><p>📌 实际上，如果我们有一个真实类型的input对象，我们可以使用output=alexnet(input)运行正向传播。 ⏱ 2023-09-30 16:34:54</p></blockquote><blockquote><p>📌 网络本身就是一块白板，或者说是随机的白板，我们现在要做的就是从头训练它或加载之前训练好的网络。 ⏱ 2023-09-30 16:35:48</p></blockquote><blockquote><p>📌 我们回到models模块。我们已经知道首字母大写的名称对应实现了许多流行模型的Python类，而首字母小写的名称是指用预定义的层和单元数实例化模型的函数，可以选择性地下载和加载预先训练好的权重。 ⏱ 2023-09-30 16:36:30</p></blockquote><blockquote><p>📌 客观地说，在2015年ResNet出现之前，在如此深的网络中达到稳定的训练是极其困难的。ResNet提出了一个技巧使之变为可能，并在这一年一举击败了好几个深度学习测试基准。 ⏱ 2023-09-30 16:50:10</p></blockquote><blockquote><p>📌 我们在这里看到的是许多模块（modules），每行一个。请注意，它们与Python模块没有任何关系：它们是独立的操作，是神经网络的构建模块。它们在其他深度学习框架中也被称为层（layers）。 ⏱ 2023-09-30 16:58:08</p></blockquote><blockquote><p>📌 可以像调用函数一样调用resnet变量，将一幅或多幅图像作为输入，并为1000个ImageNet类生成对等数量的分数 ⏱ 2024-11-11 16:19:37</p></blockquote><blockquote><p>📌 此之前我们必须对输入的图像进行预处理，使其大小正确，使其值（颜色）大致处于相同的数值范围。为此，TorchVision模块提供了转换操作，允许我们快速定义基本预处理函数的管道。 ⏱ 2023-09-30 16:59:30</p></blockquote><blockquote><p>📌 并将其转换为一个张量，对其RGB分量（红色、绿色和蓝色）进行归一化处理，使其具有定义的均值和标准差。张量是一种PyTorch多维数组 ⏱ 2023-09-30 17:01:18</p></blockquote><blockquote><p>📌 在深度学习中，在新数据上运行训练过的模型的过程被称为推理（inference）。为了进行推理，我们需要将网络置于eval模式。 ⏱ 2023-09-30 17:23:07</p></blockquote><blockquote><p>📌 如果我们忘记这样做，那么一些预先训练过的模型，如批归一化（Batch Normalization）和Dropout将不会产生有意义的答案，这仅仅是因为它们内部工作的方式。现在eval设置好了，我们准备进行推理。 ⏱ 2023-09-30 17:23:37</p></blockquote><blockquote><p>📌 一组涉及4450万个参数的惊人操作才刚刚开始。最终产生了一个拥有1000个分数的向量，每个ImageNet类对应一个分数 ⏱ 2024-11-11 17:46:35</p></blockquote><blockquote><p>📌 几乎所有用于图像识别的模型的输出形式都与我们即将使用的输出形式类似。 ⏱ 2024-11-11 17:47:29</p></blockquote><blockquote><p>📌 此时，我们需要确定与我们之前获得的out张量中最高分对应的索引。我们可以使用PyTorch的max()函数来做到这一点，它可以输出一个张量中的最大值以及最大值所在的索引 ⏱ 2024-11-11 17:53:13</p></blockquote><blockquote><p>📌 现在我们可以使用索引来访问标签。在这里，索引不是一个普通的Python数字，而是一个拥有单元素的一维张量，如tensor([207])。因此我们需要使用index[0]获得实际的数字作为标签列表的索引。我们还可以使用torch.nn.functional.softmax()将输出归一化到[0,1]​，然后除以总和。这就给了我们一些大致类似于模型在其预测中的置信度 ⏱ 2024-11-11 17:54:32</p></blockquote><blockquote><p>📌 该网络成功与否在很大程度上取决于受试者是否在训练集中表现良好。如果我们提交一幅包含训练集之外的对象的图像，网络很可能会以相当高的可信度得出错误的答案。通过实验了解模型对未知数据的反应是很有用的。 ⏱ 2024-11-11 18:46:04</p></blockquote><h4 id="_2-2-一个足以以假乱真的预训练模型" tabindex="-1">2.2 一个足以以假乱真的预训练模型 <a class="header-anchor" href="#_2-2-一个足以以假乱真的预训练模型" aria-label="Permalink to &quot;2.2 一个足以以假乱真的预训练模型&quot;">​</a></h4><blockquote><p>📌 GAN是生成式对抗网络（generative adversarial network）的缩写 ⏱ 2024-11-12 10:41:55</p></blockquote><blockquote><p>📌 这种双网络设计对于大多数深度学习架构来说是非典型的，但是当用于实现GAN游戏时，可能会产生难以置信的结果。 ⏱ 2024-11-12 10:45:56</p></blockquote><blockquote><p>📌 图2.5显示了上述过程的大致情况。生成器的最终目标是欺骗判别器，混淆真伪图像。判别器的最终目标是发现它何时被欺骗了，同时告知生成器在生成图像中可识别的错误。 ⏱ 2024-11-12 10:46:22</p></blockquote><blockquote><p>📌 在训练结束时，生成器可以生成以假乱真的图像了，而判别器却不再能够识别出图像的真伪了。 ⏱ 2024-11-12 10:46:42</p></blockquote><blockquote><p>📌 生成器，它只从噪声和一个条件信号生成逼真的图像。这里的条件信号指属性或其他图像 ⏱ 2024-11-12 10:48:09</p></blockquote><blockquote><p>📌 这个概念的一个有趣演变是CycleGAN。CycleGAN是循环生成式对抗网络的缩写，它可以将一个领域的图像转换为另一个领域的图像，而不需要我们在训练集中显式地提供匹配对。 ⏱ 2024-11-12 12:31:37</p></blockquote><blockquote><p>📌 但有迹象表明，在不久的将来，我们可能会无法在直播视频中分辨真假 ⏱ 2024-11-12 15:30:10</p></blockquote><blockquote><p>📌 的照片。该数据集可以在异步社区本书代码地址中找到。模型的权重保存在一个扩展名为“pth”的文件中，该文件只是一个模型张量参数的pickle文件 ⏱ 2024-11-12 16:52:34</p></blockquote><blockquote><p>📌 它获取一幅图像，通过观察像素识别其中的一匹或多匹马，然后逐个修改这些像素的值，使得到的结果看起来更像一匹真的斑马。在输出中或在源代码中，我们识别不出任何类似斑马的东西，这是因为那里并没有任何类似斑马的东西。该网络就像一个脚手架，核心在于权重。 ⏱ 2024-11-12 17:14:11</p></blockquote><blockquote><p>📌 使用对抗性训练或其他方法已开发出了许多其他有趣的生成器。其中一些能够创造出可信的但不存在的人脸，另一些能够将草图转化为想象中的风景的真实图片。生成模型也被用于生成真实的音频、可信的文本和令人愉快的音乐。很可能这些模型将成为支持创新过程的未来工具的基础。 ⏱ 2024-11-12 18:10:21</p></blockquote><blockquote><p>📌 工具的质量只会变得更高，应用只会变得更普遍。特别是面部交换技术，已经得到了相当多的媒体关注 ⏱ 2024-11-12 18:13:18</p></blockquote><blockquote><p>📌 到目前为止，我们已经有机会使用一个可以看到图像的模型和一个生成新图像的模型。接下来我们将以另外一个模型结束我们的旅程，该模型涉及另一个基本要素：自然语言。 ⏱ 2024-11-12 18:14:14</p></blockquote><h4 id="_2-3-一个描述场景的预训练网络" tabindex="-1">2.3 一个描述场景的预训练网络 <a class="header-anchor" href="#_2-3-一个描述场景的预训练网络" aria-label="Permalink to &quot;2.3 一个描述场景的预训练网络&quot;">​</a></h4><blockquote><p>📌 当提供一幅自然图像时，这个模型会生成一段关于场景的英文说明，如图2.9所示。该模型是在一幅巨大的图像和与之相应的英文说明的数据集上训练的，例如一只大花猫倚靠在木桌上，一只爪子放在激光鼠标上，另一只爪子放在黑色笔记本计算机上[3]。 ⏱ 2024-11-12 18:16:23</p></blockquote><blockquote><p>📌 这个字幕模型有2个相连的部分。该模型的前半部分是一个网络，它学习生成场景的“描述性”数字表征，例如本例中的大花猫、激光鼠标、爪子，然后将其作为后半部分的输入。后半部分是一个循环神经网络，它通过将这些描述性的数字放在一起产生一个连贯的句子 ⏱ 2024-11-12 18:20:06</p></blockquote><blockquote><p>📌 出。这将使下一个单词对前面生成的单词产生依赖性，就像我们在处理句子或处理序列时所期望的那样。 ⏱ 2024-11-12 18:27:12</p></blockquote><blockquote><p>📌 当然模型从未见过斑马摆出这样的姿势，也从未见过骑在斑马上的骑手，即一些非斑马的图案。此外，在训练集中通常是以组的形式描述斑马的，因此或许存在一些我们可以探究的偏差。字幕网络也没有描述骑手。同样，这可能出于相同的原因：模型在训练时训练集中没有显示骑在斑马上的骑手。总之，这都是一个令人印象深刻的壮举：我们在不可能的情况下生成了一幅假图像，并且字幕网络足够灵活，它能够正确地捕捉到主题。 ⏱ 2024-11-12 18:38:57</p></blockquote><blockquote><p>📌 在深度学习出现之前这是很难实现的。有了深度学习之后，这可以用不超过1000行的代码来实现 ⏱ 2024-11-12 18:40:06</p></blockquote><blockquote><p>📌 本例中采用的是MS COCO数据集[4]。没有硬编码的标点或语法，所有内容，包括句子，都是从数据模式中产生的。 ⏱ 2024-11-12 19:05:46</p></blockquote><blockquote><p>📌 截至撰写本书时，像这样的模型更多作为应用研究或创新项目存在，而不具有明确和具体的用途。这些模型的结果虽然还不错，但还不够好用。然而，随着时间的推移以及训练数据的扩展，我们期望这类模型能够向有视力障碍的人描述世界，从视频转述场景，以及执行其他类似的任务。 ⏱ 2024-11-12 19:06:12</p></blockquote><h4 id="_2-4-torch-hub" tabindex="-1">2.4 Torch Hub <a class="header-anchor" href="#_2-4-torch-hub" aria-label="Permalink to &quot;2.4 Torch Hub&quot;">​</a></h4><blockquote><p>📌 直到PyTorch 1.0，还没有办法确保用户有一个统一的接口来获取它们。正如我们在本章前面看到的，TorchVision是一个规范接口的好例子，但是其他设计者，如CycleGAN和NeuralTalk2的设计者，他们选择了不同的设计。 ⏱ 2024-11-12 19:12:22</p></blockquote><blockquote><p>📌 作者若要通过Torch Hub机制发布模型，只需将一个名为hubconf.py的文件放在GitHub存储库的根目录下。 ⏱ 2024-11-12 19:15:13</p></blockquote><blockquote><p>📌 在GitHub中访问TorchVision时，我们会注意到它包含一个hubconf.py文件。我们要做的第1件事就是在该文件中查找存储库的入口点，稍后我们需要指定它们。以TorchVision为例，有resnet18和resnet50，我们已经知道它们的作用：它们分别返回18层和50层ResNet模型。我们还可以看到入口点函数包含参数pretrained，该参数值如果为true，返回的模型将使用从ImageNet获得的权重进行初始化，正如我们在本章前面看到的。 ⏱ 2024-11-12 19:28:54</p></blockquote><blockquote><p>📌 录下。然后运行resnet18入口点函数，该函数返回实例化的模型。 ⏱ 2024-11-12 19:30:50</p></blockquote><blockquote><p>📌 Torch Hub不会自动安装缺少的依赖项，但会向我们报告，以便我们采取行动。 ⏱ 2024-11-12 19:30:43</p></blockquote><blockquote><p>📌 现在通过这个机制发布的每一个模型都将被我们通过同样的方式访问，这远远超出了我们的想象。 ⏱ 2024-11-12 19:31:26</p></blockquote><blockquote><p>📌 撰写本书时Torch Hub还是很新的，而且只有少数几个模型是以这种方式发布的。我们可以在谷歌上搜一下GitHub的hubconf.py文件。随着越来越多的作者通过这个机制分享他们的模型，这个清单的内容有望在未来继续丰富。 ⏱ 2024-11-12 19:35:55</p></blockquote><h4 id="_2-5-总结" tabindex="-1">2.5 总结 <a class="header-anchor" href="#_2-5-总结" aria-label="Permalink to &quot;2.5 总结&quot;">​</a></h4><blockquote><p>📌 PyTorch做得特别正确的一件事是以基本工具集的形式提供这些构建块。从API的角度来看，PyTorch并不是很大的库，尤其是与其他深度学习框架相比。 ⏱ 2024-11-12 13:34:22</p></blockquote><blockquote><p>📌 当我们拥有的数据不是特别多的时候，我们可以从一个预先训练好的网络开始，在新的数据上对它进行微调，而不是从头开始，这是解决问题的有效方法。这也是预训练网络成为深度学习实践者重要工具的另一个原因。 ⏱ 2024-11-12 13:38:33</p></blockquote><h3 id="第3章-从张量开始" tabindex="-1">第3章 从张量开始 <a class="header-anchor" href="#第3章-从张量开始" aria-label="Permalink to &quot;第3章 从张量开始&quot;">​</a></h3><blockquote><p>📌 文本。从这个角度来看，深度学习实际上需要构建一个能够将数据从一种表示转换为另一种表示的系统。这种转换是通过从论证所需映射的一系列样本中提取共性来驱动的 ⏱ 2024-11-13 00:44:32</p></blockquote><blockquote><p>📌 这个过程从将我们的输入转换为浮点数开始 ⏱ 2024-11-13 00:44:17</p></blockquote><h4 id="_3-1-实际数据转为浮点数" tabindex="-1">3.1 实际数据转为浮点数 <a class="header-anchor" href="#_3-1-实际数据转为浮点数" aria-label="Permalink to &quot;3.1 实际数据转为浮点数&quot;">​</a></h4><blockquote><p>📌 深度神经网络通常在不同阶段学习将数据从一种形式转换为另一种形式，这意味着每个阶段转换的数据可以被认为是一个中间表征序列。 ⏱ 2024-11-15 20:52:59</p></blockquote><blockquote><p>📌 一般来说，这些中间表征是浮点数的集合，它们描述输入的特征，并以一种有助于描述输入映射到神经网络输出的方式捕获数据的结构。这些描述是针对当前任务的，是从相关的例子中学习到的。这些浮点数的集合以及它们的操作是现代AI的核心 ⏱ 2024-11-15 20:52:53</p></blockquote><blockquote><p>📌 请记住，这些中间表征是将输入与前一层神经元的权重结合的结果， ⏱ 2024-11-15 20:53:52</p></blockquote><blockquote><p>📌 每个中间表征对之前的输入都是唯一的。 ⏱ 2024-11-15 20:54:16</p></blockquote><blockquote><p>📌 在深度学习中，张量可以将向量和矩阵推广到任意维度 ⏱ 2024-11-15 20:55:55</p></blockquote><blockquote><p>📌 张量的维度与用来表示张量中标量值的索引数量一致。 ⏱ 2024-11-15 20:56:16</p></blockquote><blockquote><p>📌 张量是PyTorch中用来表示数据的构建块 ⏱ 2024-11-15 21:03:14</p></blockquote><blockquote><p>📌 首先，我们将学习使用PyTorch张量库来操作张量。这包括如何将数据存储在内存中，如何在常量时间内对任意大张量执行某些操作，以及前面提到的NumPy互操作和GPU加速。如果要使张量成为我们编程工具箱中的重要工具，那么理解张量的功能和API是很重要的。在 ⏱ 2024-11-15 21:12:21</p></blockquote><h4 id="_3-2-张量-多维数组" tabindex="-1">3.2 张量：多维数组 <a class="header-anchor" href="#_3-2-张量-多维数组" aria-label="Permalink to &quot;3.2 张量：多维数组&quot;">​</a></h4><blockquote><p>📌 张量是一个数组，也就是一种数据结构，它存储了一组数字，这些数字可以用一个索引单独访问，也可以用多个索引访问。 ⏱ 2024-11-15 21:19:07</p></blockquote><blockquote><p>📌 第4章我们将看到，使用更有效的张量数据结构，从图像到时间序列等许多类型的数据，甚至是句子都可以表示出来。 ⏱ 2024-11-18 22:36:02</p></blockquote><blockquote><p>📌 Python列表或数字元组是在内存中单独分配的Python对象的集合，如图3.3左侧所示。另外，PyTorch张量或NumPy数组通常是连续内存块的视图，这些内存块包含未装箱的C数字类型，而不是Python对象。 ⏱ 2024-11-22 09:30:37</p></blockquote><h4 id="_3-4-命名张量" tabindex="-1">3.4 命名张量 <a class="header-anchor" href="#_3-4-命名张量" aria-label="Permalink to &quot;3.4 命名张量&quot;">​</a></h4><blockquote><p>📌 但是现在我们有了权重。PyTorch将允许我们对相同形状的张量进行乘法运算，也允许与给定维度中其中一个操作数大小为1的张量进行运算。它还会自动附加大小为1的前导维度，这个特性被称为广播。 ⏱ 2024-11-22 09:34:50</p></blockquote><blockquote><p>📌 在Python中，广播（一种用来概括未命名事物的形式）通常使用三个点（…）来表示 ⏱ 2024-11-22 09:34:40</p></blockquote>',142)])])}const i=e(u,[["render",b]]);export{n as __pageData,i as default};
