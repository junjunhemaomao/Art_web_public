import{_ as i,o as a,c as t,a6 as e}from"./chunks/framework.BB0md0jN.js";const d=JSON.parse('{"title":"神经网络与深度学习","description":"","frontmatter":{"layout":"doc","title":"神经网络与深度学习","readingTime":"8 min read"},"headers":[],"relativePath":"电影和阅读/微信读书/计算机/神经网络与深度学习.md","filePath":"电影和阅读/微信读书/计算机/神经网络与深度学习.md"}'),r={name:"电影和阅读/微信读书/计算机/神经网络与深度学习.md"};function u(o,l,n,p,s,_){return a(),t("div",null,[...l[0]||(l[0]=[e('<h1 id="神经网络与深度学习" tabindex="-1">神经网络与深度学习 <a class="header-anchor" href="#神经网络与深度学习" aria-label="Permalink to &quot;神经网络与深度学习&quot;">​</a></h1><p><img src="https://wfqqreader-1252317822.image.myqcloud.com/cover/266/851266/t7_851266.jpg" alt=" 神经网络与深度学习"></p><ul><li><strong>书名</strong>： 神经网络与深度学习</li><li><strong>作者</strong>： 吴岸城</li><li><strong>简介</strong>： 本书结合日常生活中的寻常小事，生动形象地阐述了神经网络与深度学习的基本概念、原理和实践，案例丰富，深入浅出。对于正在进入人工智能时代的我们，这些内容无疑可以帮助我们更好地理解人工智能的原理，丰富我们对人类自身的认识，并启发我们对人机智能之争更深一层的思考与探索。</li><li><strong>出版时间 2016-06-01 00</strong>: 00:00</li><li><strong>ISBN</strong>： 9787121288692</li><li><strong>分类</strong>： 计算机-人工智能</li><li><strong>出版社</strong>： 电子工业出版社</li></ul><h2 id="前言" tabindex="-1">前言 <a class="header-anchor" href="#前言" aria-label="Permalink to &quot;前言&quot;">​</a></h2><ul><li>📌 所以写本书的意义在于让人们不过多地关注公式及推导过程，而是关注它的使用方法，把人类的想法迅速转换成生产力才是目的 <ul><li>⏱ 2020-12-11 11:33:02</li></ul></li></ul><h2 id="_0-写在前面-神经网络的历史" tabindex="-1">0 写在前面：神经网络的历史 <a class="header-anchor" href="#_0-写在前面-神经网络的历史" aria-label="Permalink to &quot;0 写在前面：神经网络的历史&quot;">​</a></h2><ul><li><p>📌 反向传播算法”（Backpropagation Algorithm，简称BP算法）是一种监督学习算法，常被用来训练多层感知机。</p><ul><li>⏱ 2020-12-11 11:53:37</li></ul></li><li><p>📌 神经网络由一层一层的神经元构成，层数越多就越深，所谓深度学习就是用很多层神经元构成的神经网络达到机器学习的功能。</p><ul><li>⏱ 2020-12-11 11:54:19</li></ul></li><li><p>📌 随着层次的增加，学习的精确性得到提升，同时该技术还极大地推动了非监督学习的发展，让机器具备“自学”的能力。</p><ul><li>⏱ 2020-12-11 11:54:40</li></ul></li><li><p>📌 。吴恩达于2014年加入百度，成为百度首席科学家，全面负责百度研究院，参与“百度大脑”计划。“百度大脑”融合了深度学习算法、数据建模、大规模GPU并行化平台等技术，模拟神经元参数超过200亿个。</p><ul><li>⏱ 2020-12-11 11:55:46</li></ul></li></ul><h2 id="_1-3-先来看看大脑如何学习" tabindex="-1">1.3 先来看看大脑如何学习 <a class="header-anchor" href="#_1-3-先来看看大脑如何学习" aria-label="Permalink to &quot;1.3 先来看看大脑如何学习&quot;">​</a></h2><ul><li><p>📌 我们在学习、思考和识别事物时，基本原理比较简单：就是一个线路连接问题</p><ul><li>⏱ 2020-12-11 12:00:42</li></ul></li><li><p>📌 当处理中心觉察出某种模式时，将它编译后存储到脑内相应的记忆区</p><ul><li>⏱ 2020-12-11 12:02:21</li></ul></li><li><p>📌 以后，每当我们接触到这个模式，比如每次看到猴子的时候这个神经回路都会被加强，每个处理区块之间的连接会变得更稳定、更高效。对它的记忆将变得越来越牢固，回忆起来也越来越容易。</p><ul><li>⏱ 2020-12-11 12:04:04</li></ul></li><li><p>📌 。大脑思考得越多，就会发现已经储存的模式中关联越多，发现的关联越多，我们就开始理解信息的分类规则，以及各种细微的差别。</p><ul><li>⏱ 2020-12-11 12:04:24</li></ul></li><li><p>📌 知识的学习掌握，是某种程度上记忆构建的过程，</p><ul><li>⏱ 2020-12-11 12:05:06</li></ul></li></ul><h2 id="_1-4-生物意义上的神经元" tabindex="-1">1.4 生物意义上的神经元 <a class="header-anchor" href="#_1-4-生物意义上的神经元" aria-label="Permalink to &quot;1.4 生物意义上的神经元&quot;">​</a></h2><ul><li><p>📌 神经元的兴奋性具有一种很特殊的现象，当刺激强度未达到某一阈限值时（限值的概念为人工神经元模仿提供了理论依据，传输函数中大多数函数都是依据此原则来输出的），神经冲动不会发生，而当刺激强度达到该值时，神经冲动发生并能瞬时达到最大强度，此后刺激强度即使再继续加强或减弱，已诱发的冲动强度也不再发生变化。请大家深刻理解这个特性，兴奋性的原理解释了我们为什么需要传输函数，通过了解神经元的构造也可以推出传输函数的数学构成。</p><ul><li>⏱ 2020-12-11 12:16:20</li></ul></li><li><p>📌 虽然每个神经元都十分简单，但如此大量的神经元之间非常复杂的连接却可以演化出丰富多彩的行为方式。</p><ul><li>⏱ 2020-12-11 12:17:39</li></ul></li><li><p>📌 人们通过长期的研究，进一步探明了大脑皮层是由许多不同的功能区构成的。</p><ul><li>⏱ 2020-12-11 12:18:15</li></ul></li><li><p>📌 。在每个功能区中，又包含许多负责某一个具体功能的神经元群。例如，在视觉神经区，存在着只对光线方向性产生反应的神经元。更进一步细分，某一层神经元仅对水平光线产生响应，而另一层神经元只对垂直光线产生反应（这个特性跟卷积神经网络有些关联度）。</p><ul><li>⏱ 2020-12-11 12:18:36</li></ul></li><li><p>📌 各区域所具有的功能大部分是人在后天通过对环境的适应和学习而得来的。</p><ul><li>⏱ 2020-12-11 12:18:55</li></ul></li><li><p>📌 输入（树突）输出（轴突）部分是可以由链接强度来表示的，这直接决定了神经元A在传递信号给神经元B时，信号是有强度的。</p><ul><li>⏱ 2020-12-11 12:22:53</li></ul></li></ul><h2 id="_1-5-大脑如何解决现实生活中的分类问题" tabindex="-1">1.5 大脑如何解决现实生活中的分类问题 <a class="header-anchor" href="#_1-5-大脑如何解决现实生活中的分类问题" aria-label="Permalink to &quot;1.5 大脑如何解决现实生活中的分类问题&quot;">​</a></h2><ul><li>📌 人在学习知识，认识自然的过程中，有个基本的能力就是对已知事物进行学习，对已知或未知的事物进行分类，而对于人或物体的分类又是人类基于学习到的知识的一个逻辑推理过程。 <ul><li>⏱ 2020-12-11 12:23:50</li></ul></li></ul><h2 id="_2-构造神经网络" tabindex="-1">2 构造神经网络 <a class="header-anchor" href="#_2-构造神经网络" aria-label="Permalink to &quot;2 构造神经网络&quot;">​</a></h2><ul><li><p>📌 实际上，信号处理是归纳了所有神经元输入结果，并将其作为一个结果输出，</p><ul><li>⏱ 2020-12-11 12:28:06</li></ul></li><li><p>📌 ，然而对于一个分类运算来说，大多数时候，我们需要输出一个0或1，代表是或否，怎么处理呢？如果大于0，我们就把它作为1，如果小于0，我们就把它输出为0，</p><ul><li>⏱ 2020-12-11 12:28:48</li></ul></li></ul>',15)])])}const c=i(r,[["render",u]]);export{d as __pageData,c as default};
