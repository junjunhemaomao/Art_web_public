import{_ as e,o as t,c as l,a6 as c}from"./chunks/framework.BB0md0jN.js";const i=JSON.parse('{"title":"Python爬虫开发：从入门到实战（微课版）","description":"","frontmatter":{"layout":"doc","title":"Python爬虫开发：从入门到实战（微课版）","readingTime":"15 min read"},"headers":[],"relativePath":"电影和阅读/微信读书/计算机_编程设计/Python爬虫开发_从入门到实战微课版.md","filePath":"电影和阅读/微信读书/计算机_编程设计/Python爬虫开发_从入门到实战微课版.md"}'),a={name:"电影和阅读/微信读书/计算机_编程设计/Python爬虫开发_从入门到实战微课版.md"};function u(b,o,p,q,r,n){return t(),l("div",null,[...o[0]||(o[0]=[c('<h1 id="python爬虫开发-从入门到实战-微课版" tabindex="-1">Python爬虫开发：从入门到实战（微课版） <a class="header-anchor" href="#python爬虫开发-从入门到实战-微课版" aria-label="Permalink to &quot;Python爬虫开发：从入门到实战（微课版）&quot;">​</a></h1><p><img src="https://cdn.weread.qq.com/weread/cover/48/YueWen_23773743/t6_YueWen_23773743.jpg" alt=" Python爬虫开发：从入门到实战（微课版）"></p><ul><li><strong>书名</strong>： Python爬虫开发：从入门到实战（微课版）</li><li><strong>作者</strong>： 谢乾坤</li><li><strong>简介</strong>： 本书较为全面地介绍了定向爬虫的开发过程、各种反爬虫机制的破解方法和爬虫开发的相关技巧。全书共13章，包括绪论、Python基础、正则表达式与文件操作、简单的网页爬虫开发、高性能HTML内容解析、Python与数据库、异步加载与请求头、模拟登录与验证码、抓包与中间人爬虫、Android原生App爬虫、Scrapy、Scrapy应用、爬虫开发中的法律和道德问题等。除第 1、12、13章外的其他章末尾都有动手实践，以帮助读者巩固本章和前面章节所学的内容。</li><li><strong>出版时间</strong>： 2018-09-01 00:00:00</li><li><strong>ISBN</strong>： 9787115490995</li><li><strong>分类</strong>： 计算机-编程设计</li><li><strong>出版社</strong>： 人民邮电出版社</li><li><strong>PC地址</strong>： <a href="https://weread.qq.com/web/reader/e30323f0716ac22fe3092b2" target="_blank" rel="noreferrer">https://weread.qq.com/web/reader/e30323f0716ac22fe3092b2</a></li></ul><h3 id="_1-1-爬虫" tabindex="-1">1.1 爬虫 <a class="header-anchor" href="#_1-1-爬虫" aria-label="Permalink to &quot;1.1 爬虫&quot;">​</a></h3><blockquote><p>📌 驾驭爬虫，监控酒店的房价变化只是基本技能。 ⏱ 2019-11-02 13:40:19</p></blockquote><h3 id="_1-3-爬虫开发技术" tabindex="-1">1.3 爬虫开发技术 <a class="header-anchor" href="#_1-3-爬虫开发技术" aria-label="Permalink to &quot;1.3 爬虫开发技术&quot;">​</a></h3><blockquote><p>📌 访问频率检查、验证码、登录验证、行为检测。 ⏱ 2019-11-02 13:42:53</p></blockquote><blockquote><p>📌 将中间人攻击技术与爬虫结合在一起，再把Android自动化测试技术与爬虫结合在一起，从而构造一个超级自动化爬虫 ⏱ 2019-11-02 13:43:18</p></blockquote><blockquote><p>📌 分布式爬虫框架Scrapy ⏱ 2019-11-02 13:44:15</p></blockquote><h3 id="_2-3-python的数据结构和控制结构" tabindex="-1">2.3 Python的数据结构和控制结构 <a class="header-anchor" href="#_2-3-python的数据结构和控制结构" aria-label="Permalink to &quot;2.3 Python的数据结构和控制结构&quot;">​</a></h3><blockquote><p>📌 元组和列表的区别：列表生成以后还可以往里面继续添加数据，也可以从里面删除数据；但是元组一旦生成就不能修改。 ⏱ 2019-11-02 14:22:16</p></blockquote><blockquote><p>📌 但是如果元组里面包含了一个列表，那么这个元组里面的列表依旧可以变化。 ⏱ 2019-11-02 14:22:28</p></blockquote><blockquote><p>📌 元组和字符串不能添加新的内容，不能修改元组里面的非可变容器元素，也不能修改字符串里面的某一个字符。 ⏱ 2019-11-02 14:24:03</p></blockquote><blockquote><p>📌 集合是使用大括号括起来的各种数据，可以看作没有Value的字典。集合里面的元素不能重复。集合也是无序的。 ⏱ 2019-11-02 14:24:18</p></blockquote><blockquote><p>📌 某些时候不需要继续执行的情况，此时需要使用continue关键字来跳过本次循环。 ⏱ 2019-11-02 14:25:05</p></blockquote><blockquote><p>📌 continue只会影响到本次循环，后面的循环不受影响。当遇到某些情况时，需要结束整个循环，这个时候需要使用break关键字。 ⏱ 2019-11-02 14:25:21</p></blockquote><h3 id="_2-4-函数与类" tabindex="-1">2.4 函数与类 <a class="header-anchor" href="#_2-4-函数与类" aria-label="Permalink to &quot;2.4 函数与类&quot;">​</a></h3><blockquote><p>📌 一个函数有至少一个返回值，可以人为指定返回任何类型的数据。如果没有人为指定，那么返回值为None，返回值的个数可以是一个，也可以是多个。函数的返回值可以是另一个函数。 一个函数可以没有return语句，可以有一个return语句，也可以有多个return语句。 ⏱ 2021-05-15 15:56:25</p></blockquote><blockquote><p>📌 在函数中，可以使用return将里面的结果返回出来。代码一旦运行到了return，那么函数就会结束，return后面的代码都不会被执行。 ⏱ 2021-05-15 15:56:46</p></blockquote><blockquote><p>📌 一个函数只做一件事情，Python编码规范建议一个函数的函数体不超过20行代码。如果超过了，说明这个函数做了不止一件事情，就应该把这个函数拆分为更小的函数。这也就暗示了在函数体里面也可以调用其他的函数。 ⏱ 2019-11-02 14:33:09</p></blockquote><blockquote><p>📌 这个函数没有参数，它负责接收用户的输入。这里用到了Python的input关键字，这个关键字可以接收用户输入的字符串，并将得到的字符串返回给一个变量。 ⏱ 2019-11-02 14:33:59</p></blockquote><blockquote><p>📌 input返回的一定是一个字符串 ⏱ 2019-11-02 14:34:15</p></blockquote><blockquote><p>📌 图中的代码里面可以看到，3个函数是按顺序独立运行的，后一个函数的输入是前一个函数的输出。数据流将3个函数连起来了。 ⏱ 2021-05-15 16:20:14</p></blockquote><blockquote><p>📌 函数之间可以串行运行，数据先由一个函数处理，再由另一个函数处理；函数也可以嵌套运行，在一个函数里面调用另一个函数。 ⏱ 2019-11-02 14:35:49</p></blockquote><blockquote><p>📌 函数参数的类型决定了它的作用范围 函数外面的容器类作为参数传递到函数中以后，如果函数修改了这个容器里面的值，那么函数外面的容器也会受到影响。但是函数外面的普通变量作为参数传递到函数中，并且函数修改了这个参数的时候，外面的变量不受影响。 ⏱ 2021-05-15 16:51:46</p></blockquote><blockquote><p>📌 当要判断一个变量里面的值是不是None的时候，可以使用“is”这个关键字，也可以使用“==”。一般建议使用“is”关键字，因 ⏱ 2020-01-20 01:50:50</p></blockquote><blockquote><p>📌 对象可以只有属性没有方法，也可以只有方法没有属性。 ⏱ 2019-11-02 14:43:55</p></blockquote><blockquote><p>📌 在Python以及其他支持面向对象的编程语言中，要创建每一个具体的对象，都需要先创建类。 ⏱ 2021-05-15 16:58:37</p></blockquote><blockquote><p>📌 · 初始化方法（在有些编程语言中叫作构造函数）； ⏱ 2019-11-02 14:44:48</p></blockquote><blockquote><p>📌 object是Python内置的一个对象，开发者自己写的类需要继承于这个object或者继承自己写的其他类。 ⏱ 2021-05-15 17:17:54</p></blockquote><blockquote><p>📌 开发者自己创建的第1个类一般来说需要继承于这个object ⏱ 2021-05-15 17:20:24</p></blockquote><blockquote><p>📌 在类的外面，把类初始化为一个对象以后，可以使用“对象.属性”的格式来获得这个对象的属性；可以使用“对象．方法名(参数)”的格式来执行对象的方法，这很像是调用一个函数。其实可以理解为，方法就是类里面的函数。 ⏱ 2021-05-15 19:36:48</p></blockquote><blockquote><p>📌 在类的内部，如果要运行它自己的方法，那么调用的时候需要使用“self.方法名(参数)”的形式。如果要让一个变量在这个类的所有方法里面都能直接使用，就需要把变量初始化为“self．变量名”。 ⏱ 2019-11-02 14:45:56</p></blockquote><blockquote><p>📌 是否使用面向对象编程与代码能否正常运行没有任何关系。使用面向对象编程或者使用函数都可以实现相同的功能。区别在于写代码、读代码和改代码的“人”。面向对象编程的作用是方便代码的开发和维护。 ⏱ 2021-05-15 19:46:45</p></blockquote><blockquote><p>📌 那么如何阅读一个使用面向对象思想开发的程序呢？基本思路如下。① 这个类有哪些属性（看外貌）。② 这个类有哪些方法（能做什么）。③ 这些方法在哪里被调用（做了什么）。④ 这些方法的实现细节（怎么做的）。 ⏱ 2019-11-02 14:46:37</p></blockquote><blockquote><p>📌 先看__init__()构造函数中定义的各个属性，了解这个类的“外貌”。 ⏱ 2019-11-02 14:47:44</p></blockquote><blockquote><p>📌 首先，机器人这个类被初始化为一个对象，这个对象赋值给robot这个变量。在初始化的时候，构造函数自动执行，所以__init__里面的语句都会执行，将属性初始化。 ⏱ 2019-11-02 14:49:15</p></blockquote><h3 id="_3-1-正则表达式" tabindex="-1">3.1 正则表达式 <a class="header-anchor" href="#_3-1-正则表达式" aria-label="Permalink to &quot;3.1 正则表达式&quot;">​</a></h3><blockquote><p>📌 任意多个除了换行符以外的任意字符” ⏱ 2020-01-20 01:04:52</p></blockquote><blockquote><p>📌 问号最大的用处是与点号和星号配合起来使用，构成“.*? ”。通过正则表达式来提取信息的时候，用到最多的也是这个组合。 ⏱ 2020-01-20 01:08:12</p></blockquote><blockquote><p>📌 反斜杠放在星号的前面，写成“*”可以把星号变成普通的字符，不再具有正则表达式的意义。因此，正则表达式可以写成： 我的密码是*.**不包括最外层星号。 ⏱ 2020-01-20 01:11:03</p></blockquote><blockquote><p>📌 “\\n”代表换行符。在Python开发中，经常遇到的转义字符，如表3-1所示。 ⏱ 2020-01-20 01:11:54</p></blockquote><blockquote><p>📌 小括号可以把括号里面的内容提取出来。 ⏱ 2020-01-20 01:16:43</p></blockquote><blockquote><p>📌 如果要从一段字符串中“提取”出一部分的内容应该怎么办呢？这个时候就需要使用小括号了。 ⏱ 2020-01-20 01:17:20</p></blockquote><blockquote><p>📌 在Python中需要首先导入这个模块再进行使用。导入的语句为： import re ⏱ 2020-01-20 01:18:45</p></blockquote><blockquote><p>📌 包含一个findall方法，它能够以列表的形式返回所有满足要求的字符串。 ⏱ 2020-01-20 01:19:09</p></blockquote><blockquote><p>📌 findall的函数原型为： re.findall(pattern, string, flags=0) ⏱ 2020-01-20 01:19:22</p></blockquote><blockquote><p>📌 中文逗号和英文逗号也是不一样的。在某些字体里面，这种差异甚至无法察觉，因此在涉及正则表达式中的标点符号时，最好直接复制粘贴，而不要手动输入。 ⏱ 2020-01-20 01:23:12</p></blockquote><blockquote><p>📌 函数原型中有一个flags参数。这个参数是可以省略的。 ⏱ 2020-01-20 01:23:49</p></blockquote><blockquote><p>📌 要匹配的内容存在换行符“\\n”。要忽略换行符，就需要使用到“re.S”这个flag。 ⏱ 2020-01-20 01:24:22</p></blockquote><blockquote><p>📌 search()只会返回第1个满足要求的字符串。一旦找到符合要求的内容，它就会停止查找。对于从超级大的文本里面只找第1个数据特别有用，可以大大提高程序的运行效率。 ⏱ 2020-01-20 01:25:53</p></blockquote><blockquote><p>📌 在爬虫开发中，.*？这3个符号大多数情况下一起使用。 ⏱ 2020-01-20 01:28:27</p></blockquote><blockquote><p>📌 ．*？的意思就是匹配一个能满足要求的最短字符串。 ⏱ 2020-01-20 01:29:48</p></blockquote><blockquote><p>📌 一句话总结如下。①“.<em>”：贪婪模式，获取最长的满足条件的字符串。②“.</em>? ”：非贪婪模式，获取最短的能满足条件的字符串。 ⏱ 2020-01-20 01:31:14</p></blockquote><blockquote><p>📌 先抓大再抓小的思想会贯穿整个爬虫开发过程，一定要重点掌握。 ⏱ 2020-01-20 01:32:54</p></blockquote><h3 id="_3-4-本章小结" tabindex="-1">3.4 本章小结 <a class="header-anchor" href="#_3-4-本章小结" aria-label="Permalink to &quot;3.4 本章小结&quot;">​</a></h3><blockquote><p>📌 用得最多的组合是“(.*? )”。这个组合可以解决绝大多数的目标提取问题。 ⏱ 2019-11-02 14:57:25</p></blockquote><h2 id="第4章-简单的网页爬虫开发" tabindex="-1">第4章 简单的网页爬虫开发 <a class="header-anchor" href="#第4章-简单的网页爬虫开发" aria-label="Permalink to &quot;第4章 简单的网页爬虫开发&quot;">​</a></h2><blockquote><p>📌 requests是Python的一个第三方HTTP（Hypertext Transfer Protocol，超文本传输协议）库，它比Python自带的网络库urllib更加简单、方便和人性化。 ⏱ 2020-01-20 01:55:22</p></blockquote><h3 id="_4-1-使用python获取网页源代码" tabindex="-1">4.1 使用Python获取网页源代码 <a class="header-anchor" href="#_4-1-使用python获取网页源代码" aria-label="Permalink to &quot;4.1 使用Python获取网页源代码&quot;">​</a></h3><blockquote><p>📌 第3行使用.content这个属性来显示bytes型网页的源代码。第4行代码将bytes型的网页源代码解码为字符串型的源代码。 ⏱ 2019-11-02 15:22:24</p></blockquote><blockquote><p>📌 之所以需要把bytes型的数据解码为字符串型的数据，是因为在bytes型的数据类型下，中文是无法正常显示的。这个“解码”对应的英文为“decode”，因而我们需要使用.decode()这个方法。 ⏱ 2019-11-02 15:21:30</p></blockquote><blockquote><p>📌 在省略的时候，默认使用UTF-8编码格式来把bytes型解码为字符串型的源代码。 ⏱ 2019-11-02 15:21:40</p></blockquote><blockquote><p>📌 data这个字典的内容和项数需要根据实际情况修改，Key和Value在不同的网站是不一样的。而做爬虫，构造这个字典是任务之一。 ⏱ 2019-11-02 15:29:06</p></blockquote><blockquote><p>📌 还有一些网址，提交的内容需要是JSON格式的，因此post()方法的参数需要进行一些修改： ⏱ 2019-11-02 15:29:16</p></blockquote><h3 id="_4-2-多线程爬虫" tabindex="-1">4.2 多线程爬虫 <a class="header-anchor" href="#_4-2-多线程爬虫" aria-label="Permalink to &quot;4.2 多线程爬虫&quot;">​</a></h3><blockquote><p>📌 爬虫属于I/O密集型的程序，所以使用多线程可以大大提高爬取效率。 ⏱ 2020-01-20 02:10:55</p></blockquote>',67)])])}const h=e(a,[["render",u]]);export{i as __pageData,h as default};
