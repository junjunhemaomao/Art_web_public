import{_ as t,o as e,c as i,a6 as l}from"./chunks/framework.BB0md0jN.js";const p=JSON.parse('{"title":"AI绘画：Stable Diffusion ComfyUI的艺术","description":"","frontmatter":{"layout":"doc","title":"AI绘画：Stable Diffusion ComfyUI的艺术","readingTime":"5 min read"},"headers":[],"relativePath":"电影和阅读/微信读书/计算机_软件学习/AI绘画_Stable_Diffusion_ComfyUI的艺术.md","filePath":"电影和阅读/微信读书/计算机_软件学习/AI绘画_Stable_Diffusion_ComfyUI的艺术.md"}'),a={name:"电影和阅读/微信读书/计算机_软件学习/AI绘画_Stable_Diffusion_ComfyUI的艺术.md"};function n(r,o,f,s,u,c){return e(),i("div",null,[...o[0]||(o[0]=[l('<h1 id="ai绘画-stable-diffusion-comfyui的艺术" tabindex="-1">AI绘画：Stable Diffusion ComfyUI的艺术 <a class="header-anchor" href="#ai绘画-stable-diffusion-comfyui的艺术" aria-label="Permalink to &quot;AI绘画：Stable Diffusion ComfyUI的艺术&quot;">​</a></h1><p><img src="https://cdn.weread.qq.com/weread/cover/23/cpplatform_npbj4uyr8wnfnyyurm3d9o/t6_cpplatform_npbj4uyr8wnfnyyurm3d9o1742962956.jpg" alt=" AI绘画：Stable Diffusion ComfyUI的艺术"></p><ul><li><strong>书名</strong>： AI绘画：Stable Diffusion ComfyUI的艺术</li><li><strong>作者</strong>： 许建锋</li><li><strong>简介</strong>： 《AI绘画：Stable Diffusion ComfyUI的艺术》是《AI绘画：Stable Diffusion从入门到精通》的姐妹篇。全书系统讲解人工智能绘画中ComfyUI工具的使用，详细介绍各类ComfyUI工作流的搭建，如文生图、图生图、LoRA、ControlNet等。为了让读者更好地掌握各种节点的使用，《AI绘画：Stable Diffusion ComfyUI的艺术》还介绍了多种插件的应用，如效率节点、AnimateDiff、MimicMotion、Liveportrait、换脸、放大等。此外，为了帮助读者全面了解AI绘画的生态，《AI绘画：Stable Diffusion ComfyUI的艺术》还介绍了国内外**的科技成果，如即梦AI、可灵AI、智谱AI等。书中主要应用的模型为SDXL，也涉及SD3、Playground、Kolors（可图）、Flux等。《AI绘画：Stable Diffusion ComfyUI的艺术》内容从基础到进阶，以期帮助读者轻松掌握AI绘画的技术和应用技巧。</li><li><strong>出版时间</strong>： 2024-12-01 00:00:00</li><li><strong>ISBN</strong>： 9787302675549</li><li><strong>分类</strong>： 计算机-软件学习</li><li><strong>出版社</strong>： 清华大学出版社</li><li><strong>PC地址</strong>： <a href="https://weread.qq.com/web/reader/75032440813ab9c91g0159c9" target="_blank" rel="noreferrer">https://weread.qq.com/web/reader/75032440813ab9c91g0159c9</a></li></ul><h3 id="_2-2-模型" tabindex="-1">2.2 模型 <a class="header-anchor" href="#_2-2-模型" aria-label="Permalink to &quot;2.2 模型&quot;">​</a></h3><blockquote><p>📌 SD的三代模型之间不兼容，LoRA、ControlNet等功能只能与对应的版本匹配。 ⏱ 2025-09-30 18:18:02</p></blockquote><blockquote><p>📌 作为开源模型，Stable Diffusion允许用户对基础模型进行微调以提升生成速度。例如，SDXL模型在基础模型的基础上诞生了几类蒸馏模型 ⏱ 2025-09-30 18:40:01</p></blockquote><blockquote><p>📌 比较流行的SDXL优化模型都开发了蒸馏模型，并允许用户从网页下载。 ⏱ 2025-09-30 18:40:27</p></blockquote><blockquote><p>📌 在ComfyUI中，主模型分为Checkpoint模型、CLIP模型和UNet模型，这三种深度学习模型在结构和应用场景上有所差别。 ⏱ 2025-09-30 18:51:50</p></blockquote><blockquote><p>📌 Checkpoint模型：通常指在训练过程中某个特定时刻保存的模型状态，包括权重和优化器的状态等。Checkpoint模型保存了训练过程的中间状态，因此文件通常较大，适合需要继续训练的场景。 ⏱ 2025-09-30 18:52:20</p></blockquote><blockquote><p>📌 CLIP模型：是一种多模态预训练神经网络，它通过学习大量图像和文本的配对数据来理解图像和文本之间的关系。CLIP模型由两个主要部分组成：文本编码器和图像编码器。 ⏱ 2025-09-30 18:52:56</p></blockquote><blockquote><p>📌 UNet模型：是一种用于图像分割的卷积神经网络。UNet的结构中包含一个编码器（用于图像特征提取）和一个解码器（用于图像重建），它通过跳跃连接将编码器的输出与解码器的相应层相连，以提高分割精度。UNet模型通常用于需要精确定位和分割图像中特定结构的任务。 ⏱ 2025-09-30 18:53:25</p></blockquote><blockquote><p>📌 总结来说，Checkpoint模型侧重于保存训练过程中的状态以便后续使用，CLIP模型侧重于图文多模态任务，而UNet模型则专注于图像分割任务。我们下载的SDXL优化模型绝大部分是Checkpoint格式，而官方发布的基础模型如SD3、Kolors、Flux模型，往往采用后面两种格式。 ⏱ 2025-09-30 18:54:16</p></blockquote><blockquote><p>📌 除支持多种模型类型外，还包括编码解码模型VAE，以及LoRA模型、ControlNet等扩展使用的微调模型。每次使用时，要根据该扩展发布页面的说明，按照安装要求进行下载，并将它们复制到对应的模型目录。 ⏱ 2025-09-30 18:54:42</p></blockquote>',13)])])}const _=t(a,[["render",n]]);export{p as __pageData,_ as default};
