import{_ as e,o as t,c as i,a6 as a}from"./chunks/framework.BB0md0jN.js";const c=JSON.parse('{"title":"Python网络爬虫从入门到实践（第2版）","description":"","frontmatter":{"layout":"doc","title":"Python网络爬虫从入门到实践（第2版）","readingTime":"4 min read"},"headers":[],"relativePath":"电影和阅读/微信读书/计算机/Python网络爬虫从入门到实践第2版.md","filePath":"电影和阅读/微信读书/计算机/Python网络爬虫从入门到实践第2版.md"}'),o={name:"电影和阅读/微信读书/计算机/Python网络爬虫从入门到实践第2版.md"};function n(r,l,u,s,h,_){return t(),i("div",null,[...l[0]||(l[0]=[a('<h1 id="python网络爬虫从入门到实践-第2版" tabindex="-1">Python网络爬虫从入门到实践（第2版） <a class="header-anchor" href="#python网络爬虫从入门到实践-第2版" aria-label="Permalink to &quot;Python网络爬虫从入门到实践（第2版）&quot;">​</a></h1><p><img src="https://weread-1258476243.file.myqcloud.com/weread/cover/22/YueWen_25663552/t7_YueWen_25663552.jpg" alt=" Python网络爬虫从入门到实践（第2版）"></p><ul><li><strong>书名</strong>： Python网络爬虫从入门到实践（第2版）</li><li><strong>作者</strong>： 唐松编著</li><li><strong>简介</strong>： 使用Python编写网络爬虫程序获取互联网上的大数据是当前的热门专题。本书内容包括三部分：基础部分、进阶部分和项目实践部分。基础部分（第1~7章）主要介绍爬虫的三个步骤——获取网页、解析网页和存储数据，通过诸多示例的讲解，让读者从基础内容开始系统性地学习爬虫技术，并在实践中提升Python爬虫水平。进阶部分（第8~13章）包括多线程的并发和并行爬虫、分布式爬虫、更换IP等，帮助读者进一步提升爬虫水平。项目实践部分（第14~17章）使用本书介绍的爬虫技术对几个真实的网站进行抓取，让读者能在读完本书后根据自己的需求写出爬虫程序。无论你是否有编程基础，只要对爬虫技术感兴趣，本书就能带领你从入门到实战再到进阶，一步步了解爬虫，最终写出自己的爬虫程序。</li><li><strong>出版时间 2019-06-01 00</strong>: 00:00</li><li><strong>ISBN</strong>： 9787111626879</li><li><strong>分类</strong>： 计算机-编程设计</li><li><strong>出版社</strong>： 机械工业出版社</li></ul><h2 id="_2-3-编写第一个简单的爬虫" tabindex="-1">2.3 编写第一个简单的爬虫 <a class="header-anchor" href="#_2-3-编写第一个简单的爬虫" aria-label="Permalink to &quot;2.3 编写第一个简单的爬虫&quot;">​</a></h2><ul><li>📌 对初学者来说，使用BeautifulSoup从网页中提取需要的数据更加简单易用。 <ul><li>⏱ 2020-01-20 05:00:38</li></ul></li></ul><h2 id="第3章-静态网页抓取" tabindex="-1">第3章 静态网页抓取 <a class="header-anchor" href="#第3章-静态网页抓取" aria-label="Permalink to &quot;第3章 静态网页抓取&quot;">​</a></h2><ul><li>📌 相对而言，使用AJAX动态加载网页的数据不一定会出现在HTML代码中，这就给爬虫增加了困难。 <ul><li>⏱ 2020-01-20 05:07:09</li></ul></li></ul><h2 id="_3-3-定制requests" tabindex="-1">3.3 定制Requests <a class="header-anchor" href="#_3-3-定制requests" aria-label="Permalink to &quot;3.3 定制Requests&quot;">​</a></h2><ul><li>📌 对于爬虫而言，请求头十分重要，尽管在上一个示例中并没有制定请求头。如果没有指定请求头或请求的请求头和实际网页不一致，就可能无法返回正确的结果。 <ul><li>⏱ 2020-01-20 05:10:16</li></ul></li></ul><h2 id="_4-3-通过selenium模拟浏览器抓取" tabindex="-1">4.3 通过Selenium模拟浏览器抓取 <a class="header-anchor" href="#_4-3-通过selenium模拟浏览器抓取" aria-label="Permalink to &quot;4.3 通过Selenium模拟浏览器抓取&quot;">​</a></h2><ul><li><p>📌 在Selenium之前的版本中，这样做是不会报错的，但是Selenium新版无法正常运行。我们要下载geckodriver，</p><ul><li>⏱ 2020-01-21 18:24:49</li></ul></li><li><p>📌 其中，xpath和css_selector是比较好的方法，一方面比较清晰，另一方面相对其他方法定位元素比较准确。</p><ul><li>⏱ 2020-01-21 18:23:09</li></ul></li><li><p>📌 使用Selenium和使用浏览器“检查”的方法爬取动态网页相比，因为Selenium要在整个网页加载出来后才开始爬取内容，速度往往较慢。</p><ul><li>⏱ 2020-01-21 18:23:56</li></ul></li><li><p>📌 控制CSS。因为抓取过程中仅仅抓取页面的内容，CSS样式文件是用来控制页面的外观和元素放置位置的，对内容并没有影响，所以我们可以限制网页加载CSS，从而减少抓取时间。</p><ul><li>⏱ 2020-01-21 18:24:25</li></ul></li></ul>',11)])])}const m=e(o,[["render",n]]);export{c as __pageData,m as default};
