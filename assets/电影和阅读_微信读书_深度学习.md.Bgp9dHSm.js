import{_ as e,o as t,c as l,a6 as c}from"./chunks/framework.BB0md0jN.js";const i=JSON.parse('{"title":"深度学习","description":"","frontmatter":{"layout":"doc","title":"深度学习","readingTime":"15 min read"},"headers":[],"relativePath":"电影和阅读/微信读书/深度学习.md","filePath":"电影和阅读/微信读书/深度学习.md"}'),a={name:"电影和阅读/微信读书/深度学习.md"};function u(r,o,p,q,b,n){return t(),l("div",null,[...o[0]||(o[0]=[c('<h1 id="深度学习" tabindex="-1">深度学习 <a class="header-anchor" href="#深度学习" aria-label="Permalink to &quot;深度学习&quot;">​</a></h1><p><img src="https://cdn.weread.qq.com/weread/cover/15/YueWen_22651317/t6_YueWen_22651317.jpg" alt=" 深度学习"></p><ul><li><strong>书名</strong>： 深度学习</li><li><strong>作者</strong>： 伊恩·古德费洛 约书亚·本吉奥</li><li><strong>简介</strong>： 《深度学习》由全球知名的三位专家IanGoodfellow、YoshuaBengio和AaronCourville撰写，是深度学习领域奠基性的经典教材。全书的内容包括3个部分：第1部分介绍基本的数学工具和机器学习的概念，它们是深度学习的预备知识；第2部分系统深入地讲解现今已成熟的深度学习方法和技术；第3部分讨论某些具有前瞻性的方向和想法，它们被公认为是深度学习未来的研究重点。《深度学习》适合各类读者阅读，包括相关专业的大学生或研究生，以及不具有机器学习或统计背景、但是想要快速补充深度学习知识，以便在实际产品或平台中应用的软件工程师。</li><li><strong>出版时间</strong>： 2017-08-01 00:00:00</li><li><strong>ISBN</strong>： 9787115461476</li><li><strong>分类</strong>： 计算机-人工智能</li><li><strong>出版社</strong>： 人民邮电出版社</li><li><strong>PC地址</strong>： <a href="https://weread.qq.com/web/reader/e2332fe07159a1b5e232f89" target="_blank" rel="noreferrer">https://weread.qq.com/web/reader/e2332fe07159a1b5e232f89</a></li></ul><h3 id="第1章-引言" tabindex="-1">第1章 引言 <a class="header-anchor" href="#第1章-引言" aria-label="Permalink to &quot;第1章 引言&quot;">​</a></h3><blockquote><p>📌 但对计算机来说相对简单的问题得到迅速解决，比如，那些可以通过一系列形式化的数学规则来描述的问题。人工智能的真正挑战在于解决那些对人来说很容易执行、但很难形式化描述的任务，如识别人们所说的话或图像中的脸。 ⏱ 2023-09-12 09:35:55</p></blockquote><blockquote><p>📌 本书讨论一种解决方案。该方案可以让计算机从经验中学习，并根据层次化的概念体系来理解世界，而每个概念则通过与某些相对简单的概念之间的关系来定义。 ⏱ 2023-09-12 09:36:20</p></blockquote><blockquote><p>📌 层次化的概念让计算机构建较简单的概念来学习复杂概念。如果绘制出表示这些概念如何建立在彼此之上的图，我们将得到一张“深”（层次很多）的图。基于这个原因，我们称这种方法为AI深度学习（deep learning）。 ⏱ 2023-09-12 09:36:48</p></blockquote><blockquote><p>📌 一个人的日常生活需要关于世界的巨量知识。很多这方面的知识是主观的、直观的，因此很难通过形式化的方式表达清楚。计算机需要获取同样的知识才能表现出智能。人工智能的一个关键挑战就是如何将这些非形式化的知识传达给计算机。 ⏱ 2023-09-12 09:39:25</p></blockquote><blockquote><p>📌 人们设法设计出足够复杂的形式化规则来精确地描述世界 ⏱ 2023-09-12 09:42:43</p></blockquote><blockquote><p>📌 依靠硬编码的知识体系面临的困难表明，AI系统需要具备自己获取知识的能力，即从原始数据中提取模式的能力。这种能力称为机器学习（machine learning）。 ⏱ 2023-09-12 09:46:53</p></blockquote><blockquote><p>📌 这些简单的机器学习算法的性能在很大程度上依赖于给定数据的表示（representation）。 ⏱ 2023-09-12 12:15:11</p></blockquote><blockquote><p>📌 在计算机科学中，如果数据集合被精巧地结构化并被智能地索引，那么诸如搜索之类的操作的处理速度就可以成指数级地加快。 ⏱ 2023-09-12 10:25:47</p></blockquote><blockquote><p>📌 许多人工智能任务都可以通过以下方式解决：先提取一个合适的特征集，然后将这些特征提供给简单的机器学习算法。 ⏱ 2023-09-12 12:21:50</p></blockquote><blockquote><p>📌 然而，对于许多任务来说，我们很难知道应该提取哪些特征。 ⏱ 2023-09-12 12:24:50</p></blockquote><blockquote><p>📌 遗憾的是，我们难以准确地根据像素值来描述车轮看上去像什么。虽然车轮具有简单的几何形状，但它的图像可能会因场景而异，如落在车轮上的阴影、太阳照亮的车轮的金属零件、汽车的挡泥板或者遮挡的车轮一部分的前景物体等。 ⏱ 2023-09-12 12:25:14</p></blockquote><blockquote><p>📌 解决这个问题的途径之一是使用机器学习来发掘表示本身，而不仅仅把表示映射到输出。这种方法我们称之为表示学习（representation learning）。学习到的表示往往比手动设计的表示表现得更好。并且它们只需最少的人工干预，就能让AI系统迅速适应新的任务。表示学习算法只需几分钟就可以为简单的任务发现一个很好的特征集，对于复杂任务则需要几小时到几个月。手动为一个复杂的任务设计特征需要耗费大量的人工、时间和精力，甚至需要花费整个社群研究人员几十年的时间。 ⏱ 2023-09-12 12:26:18</p></blockquote><blockquote><p>📌 表示学习算法的典型例子是自编码器（autoencoder）。自编码器由一个编码器（encoder）函数和一个解码器（decoder）函数组合而成。编码器函数将输入数据转换为一种不同的表示，而解码器函数则将这个新的表示转换回原来的形式。我们期望当输入数据经过编码器和解码器之后尽可能多地保留信息，同时希望新的表示有各种好的特性，这也是自编码器的训练目标。为了实现不同的特性，我们可以设计不同形式的自编码器。 ⏱ 2023-09-12 12:32:43</p></blockquote><blockquote><p>📌 当设计特征或设计用于学习特征的算法时，我们的目标通常是分离出能解释观察数据的变差因素（factors of variation）。 ⏱ 2023-09-12 12:34:21</p></blockquote><blockquote><p>📌 在许多现实的人工智能应用中，困难主要源于多个变差因素同时影响着我们能够观察到的每一个数据。 ⏱ 2023-09-12 12:35:51</p></blockquote><blockquote><p>📌 大多数应用需要我们理清变差因素并忽略我们不关心的因素。 ⏱ 2023-09-12 12:36:02</p></blockquote><blockquote><p>📌 显然，从原始数据中提取如此高层次、抽象的特征是非常困难的。 ⏱ 2023-09-12 13:40:24</p></blockquote><blockquote><p>📌 我们可以认为不同数学函数的每一次应用都为输入提供了新的表示。 ⏱ 2023-09-12 13:41:41</p></blockquote><blockquote><p>📌 深度学习将所需的复杂映射分解为一系列嵌套的简单映射（每个由模型的不同层描述）来解决这一难题。 ⏱ 2023-09-13 08:48:09</p></blockquote><blockquote><p>📌 总之，这本书的主题——深度学习是通向人工智能的途径之一。具体来说，它是机器学习的一种，一种能够使计算机系统从经验和数据中得到提高的技术。 ⏱ 2023-09-13 08:49:59</p></blockquote><blockquote><p>📌 它将大千世界表示为嵌套的层次概念体系（由较简单概念间的联系定义复杂概念、从一般抽象概括到高级抽象表示） ⏱ 2023-09-13 08:50:16</p></blockquote><blockquote><p>📌 深度学习看似是一个全新的领域，只不过因为在目前流行的前几年它还是相对冷门的，同时也因为它被赋予了许多不同的名称（其中大部分已经不再使用），最近才成为众所周知的“深度学习”。 ⏱ 2023-09-13 08:56:39</p></blockquote><blockquote><p>📌 现代深度学习最早的前身是从神经科学的角度出发的简单线性模型。这些模型设计为使用一组n个输入x1,…,xn，并将它们与一个输出y相关联。这些模型希望学习一组权重w1,…,wn，并计算它们的输出f（x,w）=x1w1+…+xnwn。如图1.7所示，第一次神经网络研究浪潮称为控制论。 ⏱ 2023-09-13 08:59:41</p></blockquote><blockquote><p>📌 基于感知机和ADALINE中使用的函数f（x,w）的模型称为线性模型（linear model）。尽管在许多情况下，这些模型以不同于原始模型的方式进行训练，但仍是目前最广泛使用的机器学习模型。 ⏱ 2023-09-13 09:00:48</p></blockquote><blockquote><p>📌 目前大多数神经网络是基于一个称为整流线性单元（rectified linear unit）的神经单元模型。 ⏱ 2023-09-13 09:03:45</p></blockquote><blockquote><p>📌 ，虽然神经科学已经成功地启发了一些神经网络架构，但我们对用于神经科学的生物学习还没有足够多的了解，因此也就不能为训练这些架构用的学习算法提供太多的借鉴。 ⏱ 2023-09-13 09:04:15</p></blockquote><blockquote><p>📌 但是大家不应该认为深度学习在尝试模拟大脑。现代深度学习从许多领域获取灵感，特别是应用数学的基本内容，如线性代数、概率论、信息论和数值优化。 ⏱ 2023-09-13 09:04:35</p></blockquote><h3 id="第2章-线性代数" tabindex="-1">第2章 线性代数 <a class="header-anchor" href="#第2章-线性代数" aria-label="Permalink to &quot;第2章 线性代数&quot;">​</a></h3><blockquote><p>📌 线性代数主要是面向连续数学，而非离散数学， ⏱ 2023-09-16 22:24:32</p></blockquote><blockquote><p>📌 掌握好线性代数对于理解和从事机器学习算法相关工作是很有必要的，尤其对于深度学习算法而言。 ⏱ 2023-09-16 22:47:52</p></blockquote><blockquote><p>📌 有时我们需要衡量一个向量的大小。在机器学习中，我们经常使用称为范数（norm）的函数来衡量向量大小。 ⏱ 2024-05-21 23:40:30</p></blockquote><blockquote><p>📌 正如我们可以通过分解质因数来发现整数的一些内在性质，我们也可以通过分解矩阵来发现矩阵表示成数组元素时不明显的函数性质。 ⏱ 2024-05-21 23:41:21</p></blockquote><blockquote><p>📌 还有另一种分解矩阵的方法，称为奇异值分解（singular value decomposition, SVD），是将矩阵分解为奇异向量（singular vector）和奇异值（singular value）。通过奇异值分解，我们会得到一些与特征分解相同类型的信息。然而，奇异值分解有更广泛的应用。每个实数矩阵都有一个奇异值分解，但不一定都有特征分解。例如，非方阵的矩阵没有特征分解，这时我们只能使用奇异值分解 ⏱ 2024-05-21 23:42:47</p></blockquote><blockquote><p>📌 线性代数是理解深度学习所必须掌握的基础数学学科之一。另一门在机器学习中无处不在的重要数学学科是概率论， ⏱ 2023-09-16 22:58:54</p></blockquote><h3 id="第3章-概率与信息论" tabindex="-1">第3章 概率与信息论 <a class="header-anchor" href="#第3章-概率与信息论" aria-label="Permalink to &quot;第3章 概率与信息论&quot;">​</a></h3><blockquote><p>📌 概率论是用于表示不确定性声明的数学框架。它不仅提供了量化不确定性的方法，也提供了用于导出新的不确定性声明（statement）的公理。在人工智能领域，概率论主要有两种用途：首先，概率法则告诉我们AI系统如何推理，据此我们设计一些算法来计算或者估算由概率论导出的表达式；其次，可以用概率和统计从理论上分析我们提出的AI系统的行为。 ⏱ 2024-05-21 23:44:00</p></blockquote><blockquote><p>📌 这是因为机器学习通常必须处理不确定量，有时也可能需要处理随机（非确定性的）量。 ⏱ 2024-05-21 23:45:43</p></blockquote><blockquote><p>📌 在很多情况下，使用一些简单而不确定的规则要比复杂而确定的规则更为实用，即使真正的规则是确定的并且我们建模的系统可以足够精确地容纳复杂的规则。 ⏱ 2024-05-21 23:46:22</p></blockquote><h3 id="第4章-数值计算" tabindex="-1">第4章 数值计算 <a class="header-anchor" href="#第4章-数值计算" aria-label="Permalink to &quot;第4章 数值计算&quot;">​</a></h3><blockquote><p>📌 机器学习算法通常需要大量的数值计算。这通常是指通过迭代过程更新解的估计值来解决数学问题的算法，而不是通过解析过程推导出公式来提供正确解的方法。常见的操作包括优化（找到最小化或最大化函数值的参数）和线性方程组的求解。 ⏱ 2024-05-21 23:52:16</p></blockquote>',44)])])}const s=e(a,[["render",u]]);export{i as __pageData,s as default};
