import{_ as i,o as u,c as a,a6 as p}from"./chunks/framework.BB0md0jN.js";const d=JSON.parse('{"title":"机器学习算法的数学解析与Python实现","description":"","frontmatter":{"layout":"doc","title":"机器学习算法的数学解析与Python实现","readingTime":"44 min read"},"headers":[],"relativePath":"电影和阅读/微信读书/计算机/机器学习算法的数学解析与Python实现.md","filePath":"电影和阅读/微信读书/计算机/机器学习算法的数学解析与Python实现.md"}'),t={name:"电影和阅读/微信读书/计算机/机器学习算法的数学解析与Python实现.md"};function e(o,l,r,n,h,s){return u(),a("div",null,[...l[0]||(l[0]=[p('<h1 id="机器学习算法的数学解析与python实现" tabindex="-1">机器学习算法的数学解析与Python实现 <a class="header-anchor" href="#机器学习算法的数学解析与python实现" aria-label="Permalink to &quot;机器学习算法的数学解析与Python实现&quot;">​</a></h1><p><img src="https://weread-1258476243.file.myqcloud.com/weread/cover/11/YueWen_27559593/t7_YueWen_27559593.jpg" alt=" 机器学习算法的数学解析与Python实现"></p><ul><li><strong>书名</strong>： 机器学习算法的数学解析与Python实现</li><li><strong>作者</strong>： 莫凡</li><li><strong>简介</strong>： 学习机器学习的动机很多，可能是实际工作需要，可能是兴趣爱好，也可能是学业要求，从每种动机的角度看，这个问题都可能有不同的答案。我认同许多人所说的求知不能太功利这一观点，不过大家的时间和精力毕竟有限，就算不去追求投入产出比，至少也应该有一个学这门知识想要达到的目的。机器学习是更偏重于应用的学问，在当下的发展也确实使得机器学习越来越像一门技能，而不仅仅是技术。初学算法时我最想学的是里面的“最强算法”，不过在第1章我将介绍，机器学习算法没有最强的，只有最合适的，对于不同的问题，对应会有不同的最合适算法。所以，我们更需要关注的应该是问题，而不是算法本身。在本书中我选择介绍市面上成熟的机器学习算法包，通过现成的算法包，就能够根据实际要解决的问题直接选择所需要的机器学习算法，从而把注意力集中在对不同算法的选择上。本书的目标读者是想要学习机器学习的学生、程序员、研究人员或者爱好者，以及想要知道机器学习是什么、为什么和怎么用的所有读者。本书第1章介绍机器学习总体背景，第2章介绍配置环境，第3章到第10章彼此独立，每一章介绍一种具体的机器学习算法，读者可以直接阅读想要了解的算法，第11章介绍了集成学习方法，这是一种组合机器学习算法的方法，也是当前在实际使用中常见又十分有效的提升性能的做法。</li><li><strong>出版时间 2020-01-01 00</strong>: 00:00</li><li><strong>ISBN</strong>： 9787111642602</li><li><strong>分类</strong>： 计算机-人工智能</li><li><strong>出版社</strong>： 机械工业出版社</li></ul><h2 id="前言" tabindex="-1">前言 <a class="header-anchor" href="#前言" aria-label="Permalink to &quot;前言&quot;">​</a></h2><ul><li><p>📌 先把模型算法的主要原理和基本结构讲清楚，让读者在脑海里勾勒出基本的轮廓，明确各种概念之间的关系，然后才深入各个细枝末节展开介绍，</p><ul><li>⏱ 2020-12-03 11:36:01</li></ul></li><li><p>📌 用机器学习算法解决实际问题才是本书的最终目的</p><ul><li>⏱ 2020-12-03 11:35:43</li></ul></li><li><p>📌 应该有一个学这门知识想要达到的目的。机器学习是更偏重于应用的学问，在当下的发展也确实使得机器学习越来越像一门技能，而不仅仅是技术。</p><ul><li>⏱ 2020-12-03 11:35:39</li></ul></li><li><p>📌 机器学习算法没有最强的，只有最合适的，对于不同的问题，对应会有不同的最合适算法。所以，我们更需要关注的应该是问题，而不是算法本身。</p><ul><li>⏱ 2020-12-03 11:35:31</li></ul></li><li><p>📌 市面上成熟的机器学习算法包，通过现成的算法包，就能够根据实际要解决的问题直接选择所需要的机器学习算法，从而把注意力集中在对不同算法的选择上。</p><ul><li>⏱ 2020-12-03 11:35:35</li></ul></li><li><p>📌 第3章到第10章彼此独立，每一章介绍一种具体的机器学习算法，读者可以直接阅读想要了解的算法，</p><ul><li>⏱ 2020-12-03 11:35:33</li></ul></li><li><p>📌 ，要介绍的第一款机器学习算法是线性回归，本章将对回归问题、线性模型和如何用线性模型解决回归问题，以及对机器学习解决问题的主要模式进行介绍。</p><ul><li>⏱ 2020-12-03 11:35:33</li></ul></li><li><p>📌 解决分类问题的算法是Logistic回归分类算法，即用线性模型结合Logistic函数解决分类问题。</p><ul><li>⏱ 2020-12-03 11:35:48</li></ul></li><li><p>📌 决策树分类算法，这是一款很重要的算法，</p><ul><li>⏱ 2020-12-03 11:36:03</li></ul></li><li><p>📌 神经网络分类算法，当前大热的深度学习就是从神经网络算法这一支发展而来的，而且大量继承了神经网络的思想和结构，可以作为了解深度学习的预备。</p><ul><li>⏱ 2020-12-03 11:35:45</li></ul></li><li><p>📌 第11章介绍集成学习方法，以及如何通过组合两个以上的机器学习模型来提升预测效果。</p><ul><li>⏱ 2020-12-03 11:35:38</li></ul></li></ul><h2 id="_1-1-什么是机器学习" tabindex="-1">1.1 什么是机器学习 <a class="header-anchor" href="#_1-1-什么是机器学习" aria-label="Permalink to &quot;1.1 什么是机器学习&quot;">​</a></h2><ul><li><p>📌 机器学习（Machine Learning）住在二环，是人工智能的核心区域，也是当前发展最迅猛的一部分</p><ul><li>⏱ 2020-12-03 11:35:53</li></ul></li><li><p>📌 深度学习（Deep Learning），其实原本是从机器学习的神经网络子算法分支发展出来的一系列成果，知识体系一脉相承，只不过近年大出风头，干脆重新起了个名字“单飞”了，</p><ul><li>⏱ 2020-12-03 11:35:40</li></ul></li></ul><h2 id="_1-2-机器学习的几个需求层次" tabindex="-1">1.2 机器学习的几个需求层次 <a class="header-anchor" href="#_1-2-机器学习的几个需求层次" aria-label="Permalink to &quot;1.2 机器学习的几个需求层次&quot;">​</a></h2><ul><li><p>📌 不过我们学知识，不是因为要学而学，而是因为有用才学的。机器学习不是“屠龙之技”，它从诞生开始就立足于解决实际问题。你要解决什么样的问题，才决定你需要学习什么样的知识，以及学到什么程度。</p><ul><li>⏱ 2020-12-03 11:35:47</li></ul></li><li><p>📌 知道自己需要什么，带着目的去学习确实才是最有效率的。</p><ul><li>⏱ 2020-12-03 11:35:36</li></ul></li><li><p>📌 刨除细枝末节，机器学习的主要原理所用到的数学知识反而较为集中，确实存在在尽可能少地介绍数学背景的同时，尽可能多地介绍机器学习算法的数学原理的可能。</p><ul><li>⏱ 2020-12-03 11:35:51</li></ul></li></ul><h2 id="_1-3-机器学习的基本原理" tabindex="-1">1.3 机器学习的基本原理 <a class="header-anchor" href="#_1-3-机器学习的基本原理" aria-label="Permalink to &quot;1.3 机器学习的基本原理&quot;">​</a></h2><ul><li><p>📌 改叫“统计模型训练”就好了很多。</p><ul><li>⏱ 2020-12-03 11:35:34</li></ul></li><li><p>📌 拟合是机器学习的主要工作。</p><ul><li>⏱ 2020-12-03 11:35:36</li></ul></li><li><p>📌 机器学习算法的结果是“猜”出来的，猜的结果受很多因素影响，</p><ul><li>⏱ 2020-12-03 11:35:37</li></ul></li><li><p>📌 机器学习的过程就是不断回答两个问题：“我猜是什么”和“我猜中没有”。这两个问题推动着学习过程不断进行，根据“我猜是什么”的结果回答“我猜中没有”，再根据“我猜中没有”的结果回答“我猜是什么”。</p><ul><li>⏱ 2020-12-03 11:35:53</li></ul></li><li><p>📌 猜数字的过程就是一个完整的机器学习过程：算法模型输出一个数值，损失函数经过计算，回馈一个偏差结果，算法模型根据这个偏差结果进行调整，再输出一个数值，周而复始，直到正确为止。这就是机器学习的学习过程，这个过程在机器学习里称作“拟合”。</p><ul><li>⏱ 2020-12-03 11:36:00</li></ul></li><li><p>📌 甚至有人认为机器学习算法中所谓的“学习”，本质就是拟合数据。</p><ul><li>⏱ 2020-12-03 11:35:55</li></ul></li><li><p>📌 ，过拟合指的是算法模型的泛化性不好，算法模型通常通过一些具体的数据集进行训练，这些数据集称为训练集，由于采集方法等一些外部因素的硬性存在，训练集数据的分布情况（也就是一些统计指标）可能与真实环境的分布情况略有不同，如果算法模型太注重细节，反而会导致真正运用于真实环境中时预测精度下降。所以，“过拟合”中所谓的“过”，其实是相对训练集而言的，</p><ul><li>⏱ 2020-12-03 11:35:56</li></ul></li></ul><h2 id="_1-4-机器学习的基本概念" tabindex="-1">1.4 机器学习的基本概念 <a class="header-anchor" href="#_1-4-机器学习的基本概念" aria-label="Permalink to &quot;1.4 机器学习的基本概念&quot;">​</a></h2><ul><li><p>📌 如果认为编程有两大组成部分，即算法和数据结构，那么机器学习的两大组成部分就是模型和数据集。</p><ul><li>⏱ 2020-12-03 11:35:58</li></ul></li><li><p>📌 在机器学习中，我们称一条数据为一个样本（Sample），形式类似一维数组。</p><ul><li>⏱ 2020-12-03 11:35:47</li></ul></li><li><p>📌 回归问题的数据集，则会包含一个连续型的数值。</p><ul><li>⏱ 2020-12-03 11:35:45</li></ul></li><li><p>📌 机器学习模型算法的运算均基于线性代数法则，不妨认为向量就是该类算法所对应的“数据结构”。一条样本数据就是以一个向量的形式输入模型的。一条监督学习数据的向量形式如下：[特征X1值，特征X2值，…, Y1值]</p><ul><li>⏱ 2020-12-03 11:35:51</li></ul></li><li><p>📌 可以将矩阵看成由向量组成的数组，形式上也非常接近二维数组。</p><ul><li>⏱ 2020-12-03 11:35:37</li></ul></li><li><p>📌 其实这个组织形式非常类似电子表格，不妨就以电子表格来对照理解。每一行就是一个样本，每一列就是一个特征维度</p><ul><li>⏱ 2020-12-03 11:35:42</li></ul></li><li><p>📌 假设函数（Hypothesis Function）将是我们机器学习大冒险中的主角。</p><ul><li>⏱ 2020-12-03 11:35:42</li></ul></li><li><p>📌 我们给假设函数灌入数据作为“燃料”，它就能产生动力输出并让学习过程运转起来。</p><ul><li>⏱ 2020-12-03 11:35:52</li></ul></li><li><p>📌 我们的机器学习之旅将是一部双主角的冒险历程，而另一大主角毫无疑问就是损失函数（Loss Function）。</p><ul><li>⏱ 2020-12-03 11:35:44</li></ul></li><li><p>📌 既然是要“逼近”，首先肯定需要通过衡量工具来度量当前距离目标是逼近了还是远离了，所以损失函数又叫目标函数。</p><ul><li>⏱ 2020-12-03 11:35:49</li></ul></li><li><p>📌 二者的关键在于对象，损失函数是针对单个样本，而成本函数则是针对整个数据集，也就是说，损失函数求得的总和就是成本函数。</p><ul><li>⏱ 2020-12-03 11:35:46</li></ul></li><li><p>📌 如果要考察整个数据集的偏差之和，那么自然就是成本函数了。可以说，损失函数与成本函数既有联系又有区别，是微观与宏观的关系。</p><ul><li>⏱ 2020-12-03 11:35:39</li></ul></li><li><p>📌 当我们开始计算这10个样本的总体偏差时，我们用到的是成本函数。成本函数是由损失函数计算得到的，不过在实际计算时，可以选择令成本函数为损失函数值的总和，也可以令成本函数是损失函数值的平均，但无论是总和还是平均，其最终目标都是希望最小化成本，从而使假设函数的预测最可靠。</p><ul><li>⏱ 2020-12-03 11:35:54</li></ul></li><li><p>📌 这里其实涉及了三个步骤，第一步是将每个样本用损失函数进行计算之后，各自得到一个损失值，损失值的和为成本函数的损失值；第二步是将成本函数的损失值作为优化方法的输入，完成对假设函数的参数调整；第三步即重复第一步，计算出新的损失值，再重复第二步，继续调整假设函数的参数。二者的关系应该就更清楚了。</p><ul><li>⏱ 2020-12-03 11:35:43</li></ul></li><li><p>📌 假设函数和损失函数是机器学习的重要概念，机器学习算法看似千差万别，但如果把算法结构都拆开来比较，肯定都是假设函数和损失函数这对固定组合，再搭配一些其他零部件。</p><ul><li>⏱ 2020-12-03 11:35:41</li></ul></li><li><p>📌 刚开始，假设函数的预测与瞎猜基本是一个意思，很不可靠。有多不可靠呢？这就得问问损失函数了。损失函数好比一把尺子，我们把假设函数的预测结果“喂”给损失函数，损失函数也会“吐”出一个结果，且通常是数值形式，以便告诉我们它与真实情况到底差了多少。</p><ul><li>⏱ 2020-12-03 11:35:34</li></ul></li><li><p>📌 我们要的是一个能进行有效预测的假设函数。</p><ul><li>⏱ 2020-12-03 11:35:59</li></ul></li><li><p>📌 不妨先把优化方法当作min(L(x))函数，就好比排序算法虽然种类众多，但经典的仅有冒泡排序、选择排序、插入排序等十多种，思路和方法不同，执行效率也各不相同，但效果是完全一样的。</p><ul><li>⏱ 2020-12-03 11:36:02</li></ul></li><li><p>📌 所以只要对损失函数采用梯度下降法，让假设函数朝着梯度的负方向更新权值，就能达到令损失值最小化的效果。</p><ul><li>⏱ 2020-12-03 11:35:31</li></ul></li><li><p>📌 梯度下降法涉及微积分学的相关知识，需要了解其背后的性质才能更好地理解。</p><ul><li>⏱ 2020-12-03 11:35:48</li></ul></li><li><p>📌 当离底杆还有一段距离时，我们会让车子一次性多倒一点，如果已经很接近底杆了，我们就会提醒司机放慢倒车速度。总之，希望能够尽快缩小车尾部和底杆的距离。梯度下降法也是如此，首先由梯度确定方向，当损失值比较大时，梯度会比较大，假设函数的参数更新幅度也会大一些，随着损失值慢慢变小，梯度也随之慢慢变小，假设函数的参数更新也就随之变小了。这就是采用梯度下降作为优化方法时，利用梯度调整假设函数的参数，最终使损失值取得最小值的过程。</p><ul><li>⏱ 2020-12-03 11:35:56</li></ul></li><li><p>📌 每次迭代都使用全部样本的，称为批量梯度下降（Batch Gradient Descent）；每次迭代只使用一个样本的，称为随机梯度下降（Stochastic Gradient Descent）。因为需要计算的样本小，随机梯度下降的迭代速度更快，但更容易陷入局部最优，而不能达到全局最优点。</p><ul><li>⏱ 2020-12-03 11:35:50</li></ul></li></ul><h2 id="_1-5-机器学习问题分类" tabindex="-1">1.5 机器学习问题分类 <a class="header-anchor" href="#_1-5-机器学习问题分类" aria-label="Permalink to &quot;1.5 机器学习问题分类&quot;">​</a></h2><ul><li><p>📌 有监督学习就是有参考答案的学习，具体来说，就是数据集中包含了预测结果，譬如在房价的数据集中，除了给出面积、楼龄等数据外，真实房价也给了出来，这就是有监督学习，而无监督学习则相反。</p><ul><li>⏱ 2020-12-03 11:35:58</li></ul></li><li><p>📌 如果预测结果是离散的，通常为分类问题，而为连续的，则为回归问题。</p><ul><li>⏱ 2020-12-03 11:35:55</li></ul></li></ul><h2 id="_1-6-常用的机器学习算法" tabindex="-1">1.6 常用的机器学习算法 <a class="header-anchor" href="#_1-6-常用的机器学习算法" aria-label="Permalink to &quot;1.6 常用的机器学习算法&quot;">​</a></h2><ul><li><p>📌 Logistic回归分类算法这可谓是线性回归算法的“孪生兄弟”，其核心思想仍然是线性方法，但套了一件名为Logistic函数的“马甲”，使得其具有解决分类问题的能力</p><ul><li>⏱ 2020-12-03 11:35:40</li></ul></li><li><p>📌 KNN分类算法该算法是本书介绍的分类算法中唯一一个不依赖数学或统计模型，纯粹依靠“生活经验”的算法，它通过“找最近邻”的思想解决分类问题，其核心思想和区块链技术中的共识机制有着深远的关系</p><ul><li>⏱ 2020-12-03 11:35:32</li></ul></li><li><p>📌 朴素贝叶斯分类算法这是一套能够刷新你世界观的算法，它认为结果不是确定性的而是概率性的，你眼前所见的不过是概率最大的结果罢了。</p><ul><li>⏱ 2020-12-03 11:35:50</li></ul></li><li><p>📌 如果说Logistic回归分类算法是最基本的线性分类算法，那么支持向量机则是线性分类算法的最高形式，</p><ul><li>⏱ 2020-12-03 11:36:00</li></ul></li><li><p>📌 该算法使用一系列令人拍案叫绝的数学技巧，将线性不可分的数据点映射成线性可分，再用最简单的线性方法来解决问题。</p><ul><li>⏱ 2020-12-03 11:36:01</li></ul></li><li><p>📌 K-means聚类算法有监督学习是当前机器学习的一种主流方式，但样本标记需要耗费大量人工成本，容易出现样本累积规模庞大，但标记不足的问题。无监督学习则是一种无须依赖标记样本的机器学习算法，聚类算法就是其中具有代表性的一种，而K-means是聚类算法中的典型代表</p><ul><li>⏱ 2020-12-03 11:35:57</li></ul></li></ul><h2 id="_1-7-机器学习算法的性能衡量指标" tabindex="-1">1.7 机器学习算法的性能衡量指标 <a class="header-anchor" href="#_1-7-机器学习算法的性能衡量指标" aria-label="Permalink to &quot;1.7 机器学习算法的性能衡量指标&quot;">​</a></h2><ul><li><p>📌 在所有的机器学习算法中，并不存在最厉害的算法。</p><ul><li>⏱ 2020-12-03 12:44:49</li></ul></li><li><p>📌 没有最好的模型，但是有最合适的模型。机器学习算法虽然只有几种，但需要解决的问题千千万万，哪种模型适合你所要解决的问题，还需要具体问题具体分析。</p><ul><li>⏱ 2020-12-03 12:45:10</li></ul></li><li><p>📌 准确率的含义是模型猜对了的结果在全部结果中的占比，猜对的越多，得分就越高。</p><ul><li>⏱ 2020-12-03 12:53:34</li></ul></li></ul><h2 id="_1-8-数据对算法结果的影响" tabindex="-1">1.8 数据对算法结果的影响 <a class="header-anchor" href="#_1-8-数据对算法结果的影响" aria-label="Permalink to &quot;1.8 数据对算法结果的影响&quot;">​</a></h2><ul><li><p>📌 数据决定了算法的能力上限</p><ul><li>⏱ 2020-12-03 12:54:20</li></ul></li><li><p>📌 在机器学习中，最重要的不是算法而是数据。有一句话我觉得很有道理——数据决定了模型能够达到的上限，而算法只是逼近这个上限。</p><ul><li>⏱ 2020-12-03 12:54:32</li></ul></li><li><p>📌 一件事可以从多个角度讲述，同样，统计时也可以有多种维度，这些统计维度就是前面所介绍的组成一条样本数据的多个特征。机器学习模型正是从这些特征中进行学习，特征有多少价值，机器才能学多少价值。如果数据是金矿，那么特征则是含金量。即便使用的是同样的模型算法，但如果用于学习的特征不同，所得结果的价值也不同，选取的特征越合适，含金量越高，最后学习到的结果也越有价值。</p><ul><li>⏱ 2020-12-03 13:03:10</li></ul></li></ul><h2 id="_2-1-常用环境" tabindex="-1">2.1 常用环境 <a class="header-anchor" href="#_2-1-常用环境" aria-label="Permalink to &quot;2.1 常用环境&quot;">​</a></h2><ul><li><p>📌 充分利用工具的便利性，快速了解掌握现有资源后，随即开始着手解决现实问题。</p><ul><li>⏱ 2020-12-03 13:05:38</li></ul></li><li><p>📌 但稳坐榜首的一直是Scikit-Learn，它不但种类齐备，市面上见得到的机器学习算法基本上都能在此找到对应的API，简直是一家“机器学习算法超市”，</p><ul><li>⏱ 2020-12-03 13:06:19</li></ul></li><li><p>📌 另外再加上一个Pandas数据处理库。它内置许多排序、统计之类的实用功能，属于“没它也不是不行，但有它会方便很多”的角色。业界实现机器学习，基本上都会用到Numpy、Scikit-Learn和Pandas这三件套。</p><ul><li>⏱ 2020-12-03 13:07:14</li></ul></li></ul><h2 id="_2-3-numpy简介" tabindex="-1">2.3 Numpy简介 <a class="header-anchor" href="#_2-3-numpy简介" aria-label="Permalink to &quot;2.3 Numpy简介&quot;">​</a></h2><ul><li>📌 Array数据类型是Numpy的核心数据结构，与Python的List类型相似，但功能要强大得多。Numpy相关功能都是围绕着Array类型建设的，可以作为你了解Numpy的一条中心线索。 <ul><li>⏱ 2020-12-03 13:15:04</li></ul></li></ul><h2 id="_2-4-scikit-learn简介" tabindex="-1">2.4 Scikit-Learn简介 <a class="header-anchor" href="#_2-4-scikit-learn简介" aria-label="Permalink to &quot;2.4 Scikit-Learn简介&quot;">​</a></h2><ul><li><p>📌 或者应该反过来，现在机器学习推荐使用Python，正是因为Python拥有Scikit-Learn这样功能强大的支持包，它已经把底层的脏活、累活都默默完成了，让使用者能够将宝贵的注意力和精力集中在解决问题上，极大地提高了产出效率。</p><ul><li>⏱ 2020-12-03 13:16:17</li></ul></li><li><p>📌 生成模型后，一般使用fit方法给模型“喂”数据及进行训练。完成训练的模型可以使用predict方法进行预测。</p><ul><li>⏱ 2020-12-03 13:21:00</li></ul></li><li><p>📌 使用过程非常简单，只要根据格式填入数据即可，不涉及额外的数学运算操作，甚至可以说只要知道机器学习算法的名字和优劣，就能直接使用，非常便利。</p><ul><li>⏱ 2020-12-03 13:21:29</li></ul></li></ul><h2 id="_2-5-pandas简介" tabindex="-1">2.5 Pandas简介 <a class="header-anchor" href="#_2-5-pandas简介" aria-label="Permalink to &quot;2.5 Pandas简介&quot;">​</a></h2><ul><li>📌 一般在学习中接触的数据都十分规整，可以直接供模型使用。但实际上，从生产环境中采集得到的“野生”数据则需要首先进行数据清洗工作，最常见的如填充丢失字段值。数据清洗工作一般使用Pandas来完成，前文所提到的特征工程也可通过Pandas完成。 <ul><li>⏱ 2020-12-03 13:22:01</li></ul></li></ul><h2 id="第3章-线性回归算法" tabindex="-1">第3章 线性回归算法 <a class="header-anchor" href="#第3章-线性回归算法" aria-label="Permalink to &quot;第3章 线性回归算法&quot;">​</a></h2><ul><li><p>📌 机器学习涉及的知识面很广，但总的来说有两条主线，一条主线是问题，另一条主线是模型。</p><ul><li>⏱ 2020-12-03 14:27:09</li></ul></li><li><p>📌 线性模型是最简单，也是最常见的机器学习模型。</p><ul><li>⏱ 2020-12-04 10:01:11</li></ul></li></ul><h2 id="_3-1-线性回归-钢铁直男-解决回归问题的正确方法" tabindex="-1">3.1 线性回归：“钢铁直男”解决回归问题的正确方法 <a class="header-anchor" href="#_3-1-线性回归-钢铁直男-解决回归问题的正确方法" aria-label="Permalink to &quot;3.1 线性回归：“钢铁直男”解决回归问题的正确方法&quot;">​</a></h2><ul><li><p>📌 在通往机器学习的路上有着各色各样的拦路虎，首先跳出来吓你一哆嗦的肯定是那些古古怪怪的术语</p><ul><li>⏱ 2020-12-04 10:03:17</li></ul></li><li><p>📌 即用线性模型来解决回归问题。</p><ul><li>⏱ 2020-12-04 10:04:07</li></ul></li><li><p>📌 回归问题是机器学习中非常经典的一类问题，换句话说，就是有许许多多的方法模型都会用于解决回归问题。</p><ul><li>⏱ 2020-12-04 10:05:48</li></ul></li><li><p>📌 机器学习是问题导向的，正因有了问题才会设计算法，这是机器学习最主要的脉络。</p><ul><li>⏱ 2020-12-04 10:06:39</li></ul></li><li><p>📌 如果也将线性回归算法比作一架机器，那线性方程和偏差度量就是组成这架机器的两大构件，</p><ul><li>⏱ 2020-12-04 10:07:05</li></ul></li><li><p>📌 两百年前，与达尔文同时代的统计学家高尔顿在研究父代与子代的身高关系时，发现一种“趋中效应”：如果父代身高高于平均值，则子代具有更高概率比他父亲要矮，简单来说就是身高回归平均值。“回归”一词也由此而来。</p><ul><li>⏱ 2020-12-04 10:08:32</li></ul></li><li><p>📌 简单来说各个数据点都沿着一条主轴来回波动的问题都算是回归问题。</p><ul><li>⏱ 2020-12-04 10:09:00</li></ul></li><li><p>📌 我刻意反复使用“历史”和“预测”这两个词，原因正是记录历史值和预测未来值是回归问题的两个代表性特征。</p><ul><li>⏱ 2020-12-04 10:11:10</li></ul></li><li><p>📌 回归问题和分类问题最大的区别在于预测结果根据预测值类型的不同，预测结果可以分为两种，一种是连续的，另一种是离散的，结果是连续的就是预测问题。</p><ul><li>⏱ 2020-12-04 10:13:12</li></ul></li><li><p>📌 连续型数值在编程时通常用int和float类型来表示，包括线性连续和非线性连续两种，</p><ul><li>⏱ 2020-12-04 10:12:54</li></ul></li><li><p>📌 相比之下，离散型数值的最大特征是缺乏中间过渡值，所以总会出现“阶跃”的现象，譬如“是”和“否”，通常用bool类型来表示，</p><ul><li>⏱ 2020-12-04 10:13:46</li></ul></li><li><p>📌 机器学习的回归模型能不能实现精准的预测呢？也许可以，不过要有条件：需要有充足的历史数据。数据的重要性怎么强调都不为过</p><ul><li>⏱ 2020-12-04 13:05:10</li></ul></li><li><p>📌 机器学习算法并不发明关系，只是关联关系的搬运工</p><ul><li>⏱ 2020-12-04 13:08:01</li></ul></li><li><p>📌 线性模型反倒更像是一个过度包装的大礼盒，大大的盒子打开一看，里面孤零零只有一样东西：线性方程</p><ul><li>⏱ 2020-12-04 13:11:05</li></ul></li><li><p>📌 线性方程就是线性回归模型的假设函数。</p><ul><li>⏱ 2020-12-04 13:11:23</li></ul></li><li><p>📌 “旋转”和“平移”就是直线的全部看家本领了</p><ul><li>⏱ 2020-12-04 13:12:40</li></ul></li><li><p>📌 这个通过调整权值来达到目的的过程叫作权值调整或者权值更新，对于线性模型而言，学习过程的主要工作就是权值调整，只要旋动旋钮，合理搭配旋转和平移这两套简单的动作，就能完成对输入数据的拟合工作，从而解决回归问题。</p><ul><li>⏱ 2020-12-04 13:14:27</li></ul></li><li><p>📌 我们还不能全面地了解这个世界，但纷繁复杂的现实世界大体还是遵循着某种规律的，我们不妨叫作“神秘方程”。而我们在机器学习领域所做的，就是通过历史数据训练模型，希望能够使我们的模型最大限度地去拟合“神秘方程”</p><ul><li>⏱ 2020-12-04 13:15:56</li></ul></li><li><p>📌 模型的能力是有上限的，能力跟不上，想最大限度地拟合也还是心有余而力不足。所以，选择模型的关键不在于模型的复杂程度，而在于数据分布。</p><ul><li>⏱ 2020-12-04 13:16:25</li></ul></li></ul><h2 id="_3-2-线性回归的算法原理" tabindex="-1">3.2 线性回归的算法原理 <a class="header-anchor" href="#_3-2-线性回归的算法原理" aria-label="Permalink to &quot;3.2 线性回归的算法原理&quot;">​</a></h2><ul><li><p>📌 机器学习最核心的概念：在错误中学习。这中间一环需要分两个步骤：首先知道偏离了多少，然后向减少偏差的方向调整权值。这个不断修正的过程就是机器学习中的“学习”</p><ul><li>⏱ 2020-12-04 13:24:20</li></ul></li><li><p>📌 偏差度量和权值调整是两个相互驱动的链条，也是机器学习中负责“学习”的部分。</p><ul><li>⏱ 2020-12-04 13:25:19</li></ul></li><li><p>📌 数学虽是一个很大很大的工具箱，具体到每款机器学习算法所使用的数学工具却非常有限。</p><ul><li>⏱ 2020-12-04 13:25:41</li></ul></li><li><p>📌 前面反复提到线性回归模型是一个过度包装的大礼盒，里面只有孤独又弱小的线性函数，它的数学表达式如下：[插图]</p><ul><li>⏱ 2020-12-04 13:43:57</li></ul></li><li><p>📌 在机器学习里面，所有假设函数都习惯用[插图]这个符号来代表预测结果。</p><ul><li>⏱ 2020-12-04 13:27:40</li></ul></li><li><p>📌 上这是个线性代数的符号，表示“转置”。如果你对线性代数不太熟悉，也不用着急心慌，“转置”是一种基础的线性代数操作，效果有点像俄罗斯方块里对长条的调整操作，如可以通过转置将行向量变成列向量，也就是把横的变成竖的。</p><ul><li>⏱ 2020-12-04 13:40:17</li></ul></li><li><p>📌 这里的w与xi不是标量（即不是数值），而分别代表着一个n维向量，如w的具体含义为w= [ w1,…,wn]。</p><ul><li>⏱ 2020-12-04 13:41:22</li></ul></li><li><p>📌 在线性代数中，这种操作被称为求两个向量的内积（Dot Product），内积所得到的结果是一个标量，也就是一个数值。</p><ul><li>⏱ 2020-12-04 13:41:37</li></ul></li><li><p>📌 无论是直线方程还是线性方程，都是与直线密切相关，区别只在于直线方程是对直线在二维平面上的刻画，而线性方程则是直线在多维空间上的刻画，自然维度要更多。</p><ul><li>⏱ 2020-12-04 13:47:34</li></ul></li><li><p>📌 这样回归模型中最重要的预测部件就已经拼装好了。给预测函数输入数据，也就是给式中的x赋值，预测函数经过计算后就能够返回一个结果，这就是预测值yˆ。</p><ul><li>⏱ 2020-12-04 13:56:59</li></ul></li><li><p>📌 真实值，在机器学习中通常用符号y来表示。既然真实值已经占用了字母y，为了区别二者，同时也为了表示二者存在密切关系，因此这才选择了[插图]作为预测值的符号，这就是假设函数为什么非要给y加顶“帽子”的原因。</p><ul><li>⏱ 2020-12-04 14:03:03</li></ul></li><li><p>📌 出现偏差，也就是线性方程作出来的直线和实际的点存在距离，应该使用更有几何意义的“距离”来度量。因此，线性回归的损失函数选择使用L2范数来度量偏差，数学表达式如下：[插图]</p><ul><li>⏱ 2020-12-04 14:03:49</li></ul></li><li><p>📌 这里只需要记住线性回归的损失函数选择的是L2范数。</p><ul><li>⏱ 2020-12-04 14:05:01</li></ul></li><li><p>📌 L2范数表示的是欧几里得距离（Euclidean Distance，又可简称为欧式距离），名字挺吓人的，其实就是小学三年级数学求的两点之间的连线长度。</p><ul><li>⏱ 2020-12-04 14:05:19</li></ul></li><li><p>📌 总之，在机器学习中，最常用的范数为L1范数和L2范数，只要知道这两个范数的含义就可以“走遍天下都不怕了”。</p><ul><li>⏱ 2020-12-04 22:07:27</li></ul></li><li><p>📌 第一步，为假设函数设定参数w，通过假设函数画出一条直线，即根据输入的点通过线性计算得到预测值。第二步，将预测值带入损失函数，计算出一个损失值。第三步，通过得到的损失值，利用梯度下降等凸优化方法，不断调整假设函数的参数w，使得损失值最小。这个不断调整参数w使得损失值最小化的过程就是线性回归的学习过程，通常称为训练模型。</p><ul><li>⏱ 2020-12-04 22:10:34</li></ul></li></ul><h2 id="_3-3-在python中使用线性回归算法" tabindex="-1">3.3 在Python中使用线性回归算法 <a class="header-anchor" href="#_3-3-在python中使用线性回归算法" aria-label="Permalink to &quot;3.3 在Python中使用线性回归算法&quot;">​</a></h2><ul><li>📌 Scikit-Learn中线性回归算法的fit方法需要传入的x和y是两组矩阵 <ul><li>⏱ 2020-12-05 00:02:07</li></ul></li></ul><h2 id="_3-4-线性回归算法的使用场景" tabindex="-1">3.4 线性回归算法的使用场景 <a class="header-anchor" href="#_3-4-线性回归算法的使用场景" aria-label="Permalink to &quot;3.4 线性回归算法的使用场景&quot;">​</a></h2><ul><li>📌 在现实环境中，要求影响因素与关注结果只是呈线性关系未免太过严苛，因此，“耿直”的线性回归只能用直线做粗略分析，所预测的结果也就不可避免的偏差过大，甚至完全失去了参考意义。 <ul><li>⏱ 2020-12-05 00:13:30</li></ul></li></ul><h2 id="_4-1-logistic回归-换上-s型曲线马甲-的线性回归" tabindex="-1">4.1 Logistic回归：换上“S型曲线马甲”的线性回归 <a class="header-anchor" href="#_4-1-logistic回归-换上-s型曲线马甲-的线性回归" aria-label="Permalink to &quot;4.1 Logistic回归：换上“S型曲线马甲”的线性回归&quot;">​</a></h2><ul><li><p>📌 分类问题听着很普通，但对于机器学习来说，分类问题是一类非常重要的问题——各种机器学习算法看似精彩纷呈，其中有相当大的一部分实际上都是围绕这一问题所设计的。</p><ul><li>⏱ 2020-12-05 00:25:23</li></ul></li><li><p>📌 线性模型披上了Logistic函数这件“马甲”，从前的“钢铁直男”摇身一变就有了S型曲线。</p><ul><li>⏱ 2020-12-05 00:26:50</li></ul></li><li><p>📌 分类问题则是有监督学习所要解决的主要问题，可谓主流中的主流，当下大部分知名的机器学习算法都是针对分类问题设计的。</p><ul><li>⏱ 2020-12-05 00:27:12</li></ul></li><li><p>📌 首先分类问题会确定有哪些类别，也就是类别是预先设定的；然后在模型训练阶段，输入的训练集样本每一条都包含了类别信息，也就是告诉你什么样的样本属于哪一类（见图4-2）。</p><ul><li>⏱ 2020-12-05 00:29:14</li></ul></li><li><p>📌 分类问题所要预测的不是数值，而是两个或两个以上的类别，机器学习算法所要完成的是预测输入属于哪个类别。</p><ul><li>⏱ 2020-12-05 00:42:54</li></ul></li><li><p>📌 如果待分类别只有两个，通常称之为二元分类（Binary Classification）问题，在机器学习中较多使用Logistic函数来解决。而若待分类别超过两个，则称之为多分类（Multi-class Classification）问题，在机器学习中较多使用Softmax函数来解决。</p><ul><li>⏱ 2020-12-05 00:43:11</li></ul></li><li><p>📌 举一个例子，现在“刷脸”功能已经随处可见，这种脸部识别功能就可以转化为分类问题。我们把所有注册用户都当成一种独立的类别，那么识别功能要做的就是根据你的特征输入进行一次“分类”，看看你究竟是不是注册用户，以及是哪位注册用户。</p><ul><li>⏱ 2020-12-05 00:43:42</li></ul></li><li><p>📌 于是又得在“关灯睡觉”和“再玩会儿”之间选择。这些大大小小的待选项其实都可看成是一种类别</p><ul><li>⏱ 2020-12-05 00:47:26</li></ul></li><li><p>📌 通过这个视角，就可以把二元分类问题和多分类问题统一起来，将多分类看成由很多个二元分类组成的分类问题，形成数据结构中的二叉搜索树。</p><ul><li>⏱ 2020-12-05 00:49:50</li></ul></li><li><p>📌 譬如分成厨余垃圾、可回收垃圾、有害垃圾等，那么用二元分类的方法，首先可以进行一次是不是厨余垃圾的分类，不是厨余垃圾的这类也就是负类，并对其继续进行一次是不是可回收垃圾的分类，沿着这套框架不断进行下去，多分类问题也就可以用二元分类问题解决，这也是许多针对二元分类问题设计的算法泛用到多分类问题领域的一种主要方式。</p><ul><li>⏱ 2020-12-05 00:50:26</li></ul></li><li><p>📌 阶跃函数的图像是不连续的，不连续的函数同样不可导。但在机器学习中，可导性非常重要，否则就无法搭配使用梯度下降等优化算法，使得偏差最小了。</p><ul><li>⏱ 2020-12-05 00:54:05</li></ul></li><li><p>📌 Logistic函数就正是这样的一款函数。它是一种可导函数，又是一种阶跃函数，或者说能够扮演类似阶跃函数的角色</p><ul><li>⏱ 2020-12-05 11:20:56</li></ul></li><li><p>📌 上面给出的Logistic函数图像是以（-10,10）这样的跨度来绘制的，呈现出了漂亮的S曲线。如果这个跨度值沿着0轴缩小，则可以看出S曲线变得越来越“直”，到了（-1,1）甚至更小时，几乎就变成了一条直线。这就是Logistic函数为什么可导</p><ul><li>⏱ 2020-12-05 11:22:28</li></ul></li><li><p>📌 Logistic函数作为阶跃函数来说，是尺度越大，效果越明显。</p><ul><li>⏱ 2020-12-05 11:23:23</li></ul></li><li><p>📌 Logistic函数有一样很便利的特性：X轴的值越是小于0,Y轴的值则越是接近于0 ; X轴的值越是大于0,Y轴的值则越是接近于1。</p><ul><li>⏱ 2020-12-05 11:25:54</li></ul></li><li><p>📌 通过Logistic函数就可以把线性模型的预测结果映射成分类问题所需的预测结果。思路如下：1）将线性模型的输出和Logistic函数的输入串接起来。2）当样本为负类时，让线性模型输出的预测值小于0，而且越小越好。3）当样本为正类时，让线性模型输出的预测值大于0，而且越大越好。</p><ul><li>⏱ 2020-12-05 11:26:12</li></ul></li></ul><h2 id="第10章-神经网络分类算法" tabindex="-1">第10章 神经网络分类算法 <a class="header-anchor" href="#第10章-神经网络分类算法" aria-label="Permalink to &quot;第10章 神经网络分类算法&quot;">​</a></h2><ul><li><p>📌 现在人们谈论“人工智能”时究竟在谈什么呢？是深度学习。那么谈论深度学习又究竟是谈什么呢？是神经网络</p><ul><li>⏱ 2020-12-04 13:28:57</li></ul></li><li><p>📌 通过神经元和兴奋传递介绍神经网络的基本结构框架，然后介绍激活函数和反向传播这两个构件，它们十分重要，一直沿用至深度学习。</p><ul><li>⏱ 2020-12-04 13:39:23</li></ul></li></ul>',43)])])}const _=i(t,[["render",e]]);export{d as __pageData,_ as default};
