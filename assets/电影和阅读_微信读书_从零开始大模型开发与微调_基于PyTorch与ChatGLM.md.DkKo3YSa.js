import{_ as e,o,c as r,a6 as a}from"./chunks/framework.BB0md0jN.js";const d=JSON.parse('{"title":"从零开始大模型开发与微调：基于PyTorch与ChatGLM","description":"","frontmatter":{"layout":"doc","title":"从零开始大模型开发与微调：基于PyTorch与ChatGLM","readingTime":"5 min read"},"headers":[],"relativePath":"电影和阅读/微信读书/从零开始大模型开发与微调_基于PyTorch与ChatGLM.md","filePath":"电影和阅读/微信读书/从零开始大模型开发与微调_基于PyTorch与ChatGLM.md"}'),c={name:"电影和阅读/微信读书/从零开始大模型开发与微调_基于PyTorch与ChatGLM.md"};function l(h,t,s,n,i,_){return o(),r("div",null,[...t[0]||(t[0]=[a('<h1 id="从零开始大模型开发与微调-基于pytorch与chatglm" tabindex="-1">从零开始大模型开发与微调：基于PyTorch与ChatGLM <a class="header-anchor" href="#从零开始大模型开发与微调-基于pytorch与chatglm" aria-label="Permalink to &quot;从零开始大模型开发与微调：基于PyTorch与ChatGLM&quot;">​</a></h1><p><img src="https://cdn.weread.qq.com/weread/cover/9/cpplatform_32qmiupxolwdoit8qmwu4y/t6_cpplatform_32qmiupxolwdoit8qmwu4y1709025868.jpg" alt=" 从零开始大模型开发与微调：基于PyTorch与ChatGLM"></p><ul><li><strong>书名</strong>： 从零开始大模型开发与微调：基于PyTorch与ChatGLM</li><li><strong>作者</strong>： 王晓华</li><li><strong>简介</strong>： 大模型是深度学习自然语言处理皇冠上的一颗明珠，也是当前AI和NLP研究与产业中最重要的方向之一。本书使用PyTorch 2.0作为学习大模型的基本框架，以ChatGLM为例详细讲解大模型的基本理论、算法、程序实现、应用实战以及微调技术，为读者揭示大模型开发技术。本书配套示例源代码、PPT课件。 《从零开始大模型开发与微调：基于PyTorch与ChatGLM》共18章，内容包括人工智能与大模型、PyTorch 2.0深度学习环境搭建、从零开始学习PyTorch 2.0、深度学习基础算法详解、基于PyTorch卷积层的MNIST分类实战、PyTorch数据处理与模型展示、ResNet实战、有趣的词嵌入、基于PyTorch循环神经网络的中文情感分类实战、自然语言处理的编码器、预训练模型BERT、自然语言处理的解码器、强化学习实战、只具有解码器的GPT-2模型、实战训练自己的ChatGPT、开源大模型ChatGLM使用详解、ChatGLM高级定制化应用实战、对ChatGLM进行高级微调。 《从零开始大模型开发与微调：基于PyTorch与ChatGLM》适合PyTorch深度学习初学者、大模型开发初学者、大模型开发人员学习，也适合高等院校人工智能、智能科学与技术、数据科学与大数据技术、计算机科学与技术等专业的师生作为教学参考书。</li><li><strong>出版时间</strong>： 2023-11-01 00:00:00</li><li><strong>ISBN</strong>： 9787302647072</li><li><strong>分类</strong>： 计算机-人工智能</li><li><strong>出版社</strong>： 清华大学出版社</li><li><strong>PC地址</strong>： <a href="https://weread.qq.com/web/reader/a4532620813ab88b3g013a2d" target="_blank" rel="noreferrer">https://weread.qq.com/web/reader/a4532620813ab88b3g013a2d</a></li></ul><h2 id="第7章-resnet实战" tabindex="-1">第7章 ResNet实战 <a class="header-anchor" href="#第7章-resnet实战" aria-label="Permalink to &quot;第7章 ResNet实战&quot;">​</a></h2><blockquote><p>📌 这个问题被称为“神经网络退化”。神经网络退化问题的产生说明了卷积神经网络不能够被简单地使用堆积层数的方法进行优化。 ⏱ 2024-11-11 20:21:34</p></blockquote><blockquote><p>📌 ResNet成为视觉乃至整个AI界的一个经典。ResNet使得训练深度达到数百甚至数千层的网络成为可能，而且性能仍然优越。 ⏱ 2024-11-11 20:22:01</p></blockquote><blockquote><p>📌 后面章节介绍的Attention模块也是基于ResNet模型的扩展，因此本章内容非常重要。 ⏱ 2024-11-11 20:26:11</p></blockquote><blockquote><p>📌 ResNet的出现彻底改变了传统靠堆积卷积层所带来的固定思维，破天荒地提出了采用模块化的集合模式来替代整体的卷积层，通过一个个模块的堆叠来替代不断增加的卷积层。 ⏱ 2024-11-11 20:22:54</p></blockquote><blockquote><p>📌 由于其表征能力强，ResNet在图像分类任务以外的许多计算机视觉应用上都取得了巨大的性能提升， ⏱ 2024-11-11 20:23:13</p></blockquote><blockquote><p>📌 使用了ResNet的结构后，可以发现层数不断加深导致的训练集上误差增大的现象被消除了，ResNet网络的训练误差会随着层数的增加而逐渐减小，并且在测试集上的表现也会变好。 ⏱ 2024-11-11 20:29:28</p></blockquote>',10)])])}const P=e(c,[["render",l]]);export{d as __pageData,P as default};
